{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and training a simple model from configurations\n",
    "\n",
    "This tutorial will walk you through how to use a configuration file to define all the parameters of a model and of the trainer. This tutorial focuses on training from SMILES data in a CSV format.\n",
    "\n",
    "The work flow of testing your code on the entire pipeline is as follows:\n",
    "\n",
    "1. Select a subset of the [available configs](https://github.com/datamol-io/graphium/tree/main/expts/hydra-configs) as a starting point.\n",
    "2. Create additional configs or modify the existing configs to suit your needs.\n",
    "3. Train or fine-tune a model with the `graphium-train` CLI.\n",
    "\n",
    "## Creating the yaml file\n",
    "\n",
    "The first step is to create a YAML file containing all the required configurations, with an example given at `graphium/expts/hydra-configs/main.yaml`. We will go through each part of the configurations. See also the README [here](https://github.com/datamol-io/graphium/tree/main/expts/hydra-configs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import omegaconf\n",
    "\n",
    "from hydra import compose, initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_config_with_key(config, key):\n",
    "    new_config = {key: config[key]}\n",
    "    print(omegaconf.OmegaConf.to_yaml(new_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yaml file loaded\n"
     ]
    }
   ],
   "source": [
    "# First, let's read the yaml configuration file\n",
    "with initialize(version_base=None, config_path=\"../../../expts/hydra-configs\"):\n",
    "    yaml_config = compose(config_name=\"main\")\n",
    "\n",
    "print(\"Yaml file loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants\n",
    "\n",
    "First, we define the constants such as the random seed and whether the model should raise or ignore an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constants:\n",
      "  name: neurips2023_small_data_gcn\n",
      "  seed: 42\n",
      "  max_epochs: 100\n",
      "  data_dir: expts/data/neurips2023/small-dataset\n",
      "  raise_train_error: true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config_with_key(yaml_config, \"constants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datamodule\n",
    "\n",
    "Here, we define all the parameters required by the datamodule to run correctly, such as the dataset path, whether to cache, the columns for the training, the molecular featurization to use, the train/val/test splits and the batch size.\n",
    "\n",
    "For more details, see class [`MultitaskFromSmilesDataModule`](https://graphium-docs.datamol.io/stable/api/graphium.data.html#graphium.data.datamodule.MultitaskFromSmilesDataModule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datamodule:\n",
      "  module_type: MultitaskFromSmilesDataModule\n",
      "  args:\n",
      "    prepare_dict_or_graph: pyg:graph\n",
      "    featurization_n_jobs: 4\n",
      "    featurization_progress: true\n",
      "    featurization_backend: loky\n",
      "    processed_graph_data_path: ../datacache/neurips2023-small/\n",
      "    num_workers: 4\n",
      "    persistent_workers: false\n",
      "    featurization:\n",
      "      atom_property_list_onehot:\n",
      "      - atomic-number\n",
      "      - group\n",
      "      - period\n",
      "      - total-valence\n",
      "      atom_property_list_float:\n",
      "      - degree\n",
      "      - formal-charge\n",
      "      - radical-electron\n",
      "      - aromatic\n",
      "      - in-ring\n",
      "      edge_property_list:\n",
      "      - bond-type-onehot\n",
      "      - stereo\n",
      "      - in-ring\n",
      "      add_self_loop: false\n",
      "      explicit_H: false\n",
      "      use_bonds_weights: false\n",
      "      pos_encoding_as_features:\n",
      "        pos_types:\n",
      "          lap_eigvec:\n",
      "            pos_level: node\n",
      "            pos_type: laplacian_eigvec\n",
      "            num_pos: 8\n",
      "            normalization: none\n",
      "            disconnected_comp: true\n",
      "          lap_eigval:\n",
      "            pos_level: node\n",
      "            pos_type: laplacian_eigval\n",
      "            num_pos: 8\n",
      "            normalization: none\n",
      "            disconnected_comp: true\n",
      "          rw_pos:\n",
      "            pos_level: node\n",
      "            pos_type: rw_return_probs\n",
      "            ksteps: 16\n",
      "    task_specific_args:\n",
      "      qm9:\n",
      "        df: null\n",
      "        df_path: ${constants.data_dir}/qm9.csv.gz\n",
      "        smiles_col: smiles\n",
      "        label_cols:\n",
      "        - A\n",
      "        - B\n",
      "        - C\n",
      "        - mu\n",
      "        - alpha\n",
      "        - homo\n",
      "        - lumo\n",
      "        - gap\n",
      "        - r2\n",
      "        - zpve\n",
      "        - u0\n",
      "        - u298\n",
      "        - h298\n",
      "        - g298\n",
      "        - cv\n",
      "        - u0_atom\n",
      "        - u298_atom\n",
      "        - h298_atom\n",
      "        - g298_atom\n",
      "        splits_path: ${constants.data_dir}/qm9_random_splits.pt\n",
      "        seed: ${constants.seed}\n",
      "        task_level: graph\n",
      "        label_normalization:\n",
      "          normalize_val_test: true\n",
      "          method: normal\n",
      "      tox21:\n",
      "        df: null\n",
      "        df_path: ${constants.data_dir}/Tox21-7k-12-labels.csv.gz\n",
      "        smiles_col: smiles\n",
      "        label_cols:\n",
      "        - NR-AR\n",
      "        - NR-AR-LBD\n",
      "        - NR-AhR\n",
      "        - NR-Aromatase\n",
      "        - NR-ER\n",
      "        - NR-ER-LBD\n",
      "        - NR-PPAR-gamma\n",
      "        - SR-ARE\n",
      "        - SR-ATAD5\n",
      "        - SR-HSE\n",
      "        - SR-MMP\n",
      "        - SR-p53\n",
      "        splits_path: ${constants.data_dir}/Tox21_random_splits.pt\n",
      "        seed: ${constants.seed}\n",
      "        task_level: graph\n",
      "      zinc:\n",
      "        df: null\n",
      "        df_path: ${constants.data_dir}/ZINC12k.csv.gz\n",
      "        smiles_col: smiles\n",
      "        label_cols:\n",
      "        - SA\n",
      "        - logp\n",
      "        - score\n",
      "        splits_path: ${constants.data_dir}/ZINC12k_random_splits.pt\n",
      "        seed: ${constants.seed}\n",
      "        task_level: graph\n",
      "        label_normalization:\n",
      "          normalize_val_test: true\n",
      "          method: normal\n",
      "    batch_size_training: 200\n",
      "    batch_size_inference: 200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config_with_key(yaml_config, \"datamodule\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture\n",
    "\n",
    "The architecture is based on [`FullGraphMultiTaskNetwork`](https://graphium-docs.datamol.io/stable/api/graphium.nn/architectures.html#graphium.nn.architectures.global_architectures.FullGraphMultiTaskNetwork).\n",
    "Here, we define all the layers for the model, including the layers for the pre-processing MLP (input layers `pre-nn` and `pre_nn_edges`), the positional encoder (`pe_encoders`), the post-processing MLP (output layers `post-nn`), and the main GNN (graph neural network `gnn`).\n",
    "\n",
    "You can find details in the following: \n",
    "- info about the positional encoder in [`graphium.nn.encoders`](https://graphium-docs.datamol.io/stable/api/graphium.nn/encoders.html)\n",
    "- info about the gnn layers in [`graphium.nn.pyg_layers`](https://graphium-docs.datamol.io/stable/api/graphium.nn/pyg_layers.html)\n",
    "- info about the architecture [`FullGraphMultiTaskNetwork`](https://graphium-docs.datamol.io/stable/api/graphium.nn/architectures.html#graphium.nn.architectures.global_architectures.FullGraphMultiTaskNetwork)\n",
    "- Main class for the GNN layers in [`BaseGraphStructure`](https://graphium-docs.datamol.io/stable/api/graphium.nn/graphium.nn.html#graphium.nn.base_graph_layer.BaseGraphStructure)\n",
    "\n",
    "The parameters allow to chose the feature size, the depth, the skip connections, the pooling and the virtual node. It also support different GNN layers such as [`GatedGCNPyg`](https://graphium-docs.datamol.io/stable/api/graphium.nn/pyg_layers.html#graphium.nn.pyg_layers.gated_gcn_pyg), [`GINConvPyg`](https://graphium-docs.datamol.io/stable/api/graphium.nn/pyg_layers.html#graphium.nn.pyg_layers.gin_pyg), [`GINEConvPyg`](https://graphium-docs.datamol.io/stable/api/graphium.nn/pyg_layers.html#graphium.nn.pyg_layers.gin_pyg.GINEConvPyg), [`GPSLayerPyg`](https://graphium-docs.datamol.io/stable/api/graphium.nn/pyg_layers.html#graphium.nn.pyg_layers.gps_pyg.GPSLayerPyg), [`MPNNPlusPyg`](https://graphium-docs.datamol.io/stable/api/graphium.nn/pyg_layers.html#graphium.nn.pyg_layers.mpnn_pyg.MPNNPlusPyg).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\n",
      "  model_type: FullGraphMultiTaskNetwork\n",
      "  mup_base_path: null\n",
      "  pre_nn:\n",
      "    out_dim: 64\n",
      "    hidden_dims: 256\n",
      "    depth: 2\n",
      "    activation: relu\n",
      "    last_activation: none\n",
      "    dropout: 0.18\n",
      "    normalization: layer_norm\n",
      "    last_normalization: ${architecture.pre_nn.normalization}\n",
      "    residual_type: none\n",
      "  pre_nn_edges: null\n",
      "  pe_encoders:\n",
      "    out_dim: 32\n",
      "    pool: sum\n",
      "    last_norm: None\n",
      "    encoders:\n",
      "      la_pos:\n",
      "        encoder_type: laplacian_pe\n",
      "        input_keys:\n",
      "        - laplacian_eigvec\n",
      "        - laplacian_eigval\n",
      "        output_keys:\n",
      "        - feat\n",
      "        hidden_dim: 64\n",
      "        out_dim: 32\n",
      "        model_type: DeepSet\n",
      "        num_layers: 2\n",
      "        num_layers_post: 1\n",
      "        dropout: 0.1\n",
      "        first_normalization: none\n",
      "      rw_pos:\n",
      "        encoder_type: mlp\n",
      "        input_keys:\n",
      "        - rw_return_probs\n",
      "        output_keys:\n",
      "        - feat\n",
      "        hidden_dim: 64\n",
      "        out_dim: 32\n",
      "        num_layers: 2\n",
      "        dropout: 0.1\n",
      "        normalization: layer_norm\n",
      "        first_normalization: layer_norm\n",
      "  gnn:\n",
      "    in_dim: 64\n",
      "    out_dim: 96\n",
      "    hidden_dims: 96\n",
      "    depth: 4\n",
      "    activation: gelu\n",
      "    last_activation: none\n",
      "    dropout: 0.1\n",
      "    normalization: layer_norm\n",
      "    last_normalization: ${architecture.pre_nn.normalization}\n",
      "    residual_type: simple\n",
      "    virtual_node: none\n",
      "    layer_type: pyg:gcn\n",
      "    layer_kwargs: null\n",
      "  graph_output_nn:\n",
      "    graph:\n",
      "      pooling:\n",
      "      - sum\n",
      "      out_dim: 96\n",
      "      hidden_dims: 96\n",
      "      depth: 1\n",
      "      activation: relu\n",
      "      last_activation: none\n",
      "      dropout: ${architecture.pre_nn.dropout}\n",
      "      normalization: ${architecture.pre_nn.normalization}\n",
      "      last_normalization: none\n",
      "      residual_type: none\n",
      "  task_heads:\n",
      "    qm9:\n",
      "      task_level: graph\n",
      "      out_dim: 19\n",
      "      hidden_dims: 128\n",
      "      depth: 2\n",
      "      activation: relu\n",
      "      last_activation: none\n",
      "      dropout: ${architecture.pre_nn.dropout}\n",
      "      normalization: ${architecture.pre_nn.normalization}\n",
      "      last_normalization: none\n",
      "      residual_type: none\n",
      "    tox21:\n",
      "      task_level: graph\n",
      "      out_dim: 12\n",
      "      hidden_dims: 64\n",
      "      depth: 2\n",
      "      activation: relu\n",
      "      last_activation: none\n",
      "      dropout: ${architecture.pre_nn.dropout}\n",
      "      normalization: ${architecture.pre_nn.normalization}\n",
      "      last_normalization: none\n",
      "      residual_type: none\n",
      "    zinc:\n",
      "      task_level: graph\n",
      "      out_dim: 3\n",
      "      hidden_dims: 32\n",
      "      depth: 2\n",
      "      activation: relu\n",
      "      last_activation: none\n",
      "      dropout: ${architecture.pre_nn.dropout}\n",
      "      normalization: ${architecture.pre_nn.normalization}\n",
      "      last_normalization: none\n",
      "      residual_type: none\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config_with_key(yaml_config, \"architecture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictor\n",
    "\n",
    "In the predictor, we define the loss functions, the metrics to track on the progress bar, and all the parameters necessary for the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictor:\n",
      "  metrics_on_progress_bar:\n",
      "    qm9:\n",
      "    - mae\n",
      "    tox21:\n",
      "    - auroc\n",
      "    zinc:\n",
      "    - mae\n",
      "  loss_fun:\n",
      "    qm9: mae\n",
      "    tox21: bce_logits\n",
      "    zinc: mae\n",
      "  random_seed: ${constants.seed}\n",
      "  optim_kwargs:\n",
      "    lr: 4.0e-05\n",
      "  torch_scheduler_kwargs:\n",
      "    module_type: WarmUpLinearLR\n",
      "    max_num_epochs: ${constants.max_epochs}\n",
      "    warmup_epochs: 10\n",
      "    verbose: false\n",
      "  scheduler_kwargs: null\n",
      "  target_nan_mask: null\n",
      "  multitask_handling: flatten\n",
      "  metrics_every_n_train_steps: 300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config_with_key(yaml_config, \"predictor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "All the metrics can be defined there. If we want to use a classification metric, we can also define a threshold.\n",
    "\n",
    "See class [`graphium.trainer.metrics.MetricWrapper`](https://graphium-docs.datamol.io/stable/api/graphium.trainer.html#graphium.trainer.metrics.MetricWrapper) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics:\n",
      "  qm9:\n",
      "  - name: mae\n",
      "    metric: mae\n",
      "    target_nan_mask: null\n",
      "    multitask_handling: flatten\n",
      "    threshold_kwargs: null\n",
      "  - name: pearsonr\n",
      "    metric: pearsonr\n",
      "    threshold_kwargs: null\n",
      "    target_nan_mask: null\n",
      "    multitask_handling: mean-per-label\n",
      "  - name: r2_score\n",
      "    metric: r2_score\n",
      "    target_nan_mask: null\n",
      "    multitask_handling: mean-per-label\n",
      "    threshold_kwargs: null\n",
      "  tox21:\n",
      "  - name: auroc\n",
      "    metric: auroc\n",
      "    task: binary\n",
      "    multitask_handling: mean-per-label\n",
      "    threshold_kwargs: null\n",
      "  - name: avpr\n",
      "    metric: average_precision\n",
      "    task: binary\n",
      "    multitask_handling: mean-per-label\n",
      "    threshold_kwargs: null\n",
      "  - name: f1 > 0.5\n",
      "    metric: f1\n",
      "    multitask_handling: mean-per-label\n",
      "    target_to_int: true\n",
      "    num_classes: 2\n",
      "    average: micro\n",
      "    threshold_kwargs:\n",
      "      operator: greater\n",
      "      threshold: 0.5\n",
      "      th_on_preds: true\n",
      "      th_on_target: true\n",
      "  - name: precision > 0.5\n",
      "    metric: precision\n",
      "    multitask_handling: mean-per-label\n",
      "    average: micro\n",
      "    threshold_kwargs:\n",
      "      operator: greater\n",
      "      threshold: 0.5\n",
      "      th_on_preds: true\n",
      "      th_on_target: true\n",
      "  zinc:\n",
      "  - name: mae\n",
      "    metric: mae\n",
      "    target_nan_mask: null\n",
      "    multitask_handling: flatten\n",
      "    threshold_kwargs: null\n",
      "  - name: pearsonr\n",
      "    metric: pearsonr\n",
      "    threshold_kwargs: null\n",
      "    target_nan_mask: null\n",
      "    multitask_handling: mean-per-label\n",
      "  - name: r2_score\n",
      "    metric: r2_score\n",
      "    target_nan_mask: null\n",
      "    multitask_handling: mean-per-label\n",
      "    threshold_kwargs: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config_with_key(yaml_config, \"metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer\n",
    "\n",
    "Finally, the Trainer defines the parameters for the number of epochs to train, the checkpoints, and the patience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer:\n",
      "  seed: ${constants.seed}\n",
      "  model_checkpoint:\n",
      "    filename: ${constants.name}\n",
      "    save_last: true\n",
      "    dirpath: models_checkpoints/neurips2023-small-gcn/\n",
      "  trainer:\n",
      "    precision: 32\n",
      "    max_epochs: ${constants.max_epochs}\n",
      "    min_epochs: 1\n",
      "    check_val_every_n_epoch: 20\n",
      "    accumulate_grad_batches: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config_with_key(yaml_config, \"trainer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Now that we defined all the configuration files, we want to train the model. The steps are fairly easy using the config loaders, and are given below.\n",
    "\n",
    "First make sure the dataset file is downloaded. Using `config_gps_10M_pcqm4m.yaml` as an example, make sure the file specified by `df_path` in the config is available.\n",
    "In this case, we need to download `pcqm4mv2-20k.csv` into the specified directory `graphium/data/PCQM4M/pcqm4mv2-20k.csv`.\n",
    "\n",
    "After that, we can simply run a training through the CLI:\n",
    "```bash\n",
    "graphium-train\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4a99d018a205fcbcc0480c84566beaebcb91b08d0414b39a842df533e2a1d25"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
