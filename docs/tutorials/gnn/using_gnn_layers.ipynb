{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('graphium': conda)"
  },
  "interpreter": {
   "hash": "f4a99d018a205fcbcc0480c84566beaebcb91b08d0414b39a842df533e2a1d25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Using GNN layers\n",
    "\n",
    "The current library implements multiple state-of-the-art graph neural networks. In this tutorial, you will learn how to use the **GCN**, **GIN**, **Gated-GCN** and **PNA** layers in a simple `forward` context.\n",
    "\n",
    "Other layers such as **DGN** require additional positional encoding to work."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import dgl\n",
    "from copy import deepcopy\n",
    "\n",
    "from graphium.nn.dgl_layers import (\n",
    "    GCNLayer,\n",
    "    GINLayer,\n",
    "    GATLayer,\n",
    "    GatedGCNLayer,\n",
    "    PNAConvolutionalLayer,\n",
    "    PNAMessagePassingLayer,\n",
    ")\n",
    "\n",
    "_ = torch.manual_seed(42)"
   ]
  },
  {
   "source": [
    "We will first create some simple batched graphs that will be used accross the examples. Here, `bg` is a batch of 2 graphs containing random node features `bg.ndata[\"h\"]` and edge features `bg.edata[\"e\"]`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Graph(num_nodes=7, num_edges=14,\n      ndata_schemes={'h': Scheme(shape=(5,), dtype=torch.float64)}\n      edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float64)})\n"
     ]
    }
   ],
   "source": [
    "in_dim = 5          # Input node-feature dimensions\n",
    "out_dim = 11        # Desired output node-feature dimensions\n",
    "in_dim_edges = 13   # Input edge-feature dimensions\n",
    "\n",
    "# Let's create 2 simple graphs. Here the tensors represent the connectivity between nodes\n",
    "g1 = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])))\n",
    "g2 = dgl.graph((torch.tensor([0, 0, 0, 1]), torch.tensor([0, 1, 2, 0])))\n",
    "\n",
    "# We add some node features to the graphs\n",
    "g1.ndata[\"h\"] = torch.rand(g1.num_nodes(), in_dim, dtype=float)\n",
    "g2.ndata[\"h\"] = torch.rand(g2.num_nodes(), in_dim, dtype=float)\n",
    "\n",
    "# We also add some edge features to the graphs\n",
    "g1.edata[\"e\"] = torch.rand(g1.num_edges(), in_dim_edges, dtype=float)\n",
    "g2.edata[\"e\"] = torch.rand(g2.num_edges(), in_dim_edges, dtype=float)\n",
    "\n",
    "# Finally we batch the graphs in a way compatible with the DGL library\n",
    "bg = dgl.batch([g1, g2])\n",
    "bg = dgl.add_self_loop(bg)\n",
    "\n",
    "# The batched graph will show as a single graph with 7 nodes\n",
    "print(bg)\n"
   ]
  },
  {
   "source": [
    "## GCN Layer\n",
    "\n",
    "To use the GCN layer from the *Kipf et al.* paper, the steps are very simple. We create the layer with the desired attributes, and apply it to the graph.\n",
    "\n",
    "<sub>Kipf, Thomas N., and Max Welling. \"Semi-supervised classification with graph convolutional networks.\" arXiv preprint arXiv:1609.02907 (2016).</sub>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GCNLayer(5 -> 11, activation=relu)\ntorch.Size([7, 5])\ntorch.Size([7, 11])\n"
     ]
    }
   ],
   "source": [
    "# We first need to extract the node features from the graph.\n",
    "# The GCN method doesn't support edge features, so we ignore them\n",
    "graph = deepcopy(bg)\n",
    "h_in = graph.ndata[\"h\"]\n",
    "\n",
    "# We create the layer\n",
    "layer = GCNLayer(\n",
    "            in_dim=in_dim, out_dim=out_dim, \n",
    "            activation=\"relu\", dropout=.3, normalization=\"batch_norm\").to(float)\n",
    "\n",
    "# We apply the forward loop on the node features\n",
    "h_out = layer(graph, h_in)\n",
    "\n",
    "# 7 is the number of nodes, 5 number of input features and 11 number of output features\n",
    "print(layer)\n",
    "print(h_in.shape)\n",
    "print(h_out.shape)"
   ]
  },
  {
   "source": [
    "## GIN Layer\n",
    "\n",
    "To use the GIN layer from the *Xu et al.* paper, the steps are identical to GCN.\n",
    "\n",
    "<sub>Xu, Keyulu, et al. \"How powerful are graph neural networks?.\" arXiv preprint arXiv:1810.00826 (2018).</sub>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GINLayer(5 -> 11, activation=relu)\ntorch.Size([7, 5])\ntorch.Size([7, 11])\n"
     ]
    }
   ],
   "source": [
    "graph = deepcopy(bg)\n",
    "h_in = graph.ndata[\"h\"]\n",
    "layer = GINLayer(\n",
    "            in_dim=in_dim, out_dim=out_dim, \n",
    "            activation=\"relu\", dropout=.3, normalization=\"batch_norm\").to(float)\n",
    "h_out = layer(graph, h_in)\n",
    "\n",
    "print(layer)\n",
    "print(h_in.shape)\n",
    "print(h_out.shape)"
   ]
  },
  {
   "source": [
    "## GAT Layer\n",
    "\n",
    "To use the GAT layer from the *Velickovic et al.* paper, the steps are identical to GCN, but the output dimension is multiplied by the number of heads.\n",
    "\n",
    "<sub>Velickovic, Petar, et al. \"Graph attention networks.\" arXiv preprint arXiv:1710.10903 (2017).</sub>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GATLayer(5 -> 11 * 5, activation=elu)\ntorch.Size([7, 5])\ntorch.Size([7, 55])\n"
     ]
    }
   ],
   "source": [
    "graph = deepcopy(bg)\n",
    "h_in = graph.ndata[\"h\"]\n",
    "layer = GATLayer(\n",
    "            in_dim=in_dim, out_dim=out_dim, num_heads=5,\n",
    "            activation=\"elu\", dropout=.3, normalization=\"batch_norm\").to(float)\n",
    "h_out = layer(graph, h_in)\n",
    "\n",
    "print(layer)\n",
    "print(h_in.shape)\n",
    "print(h_out.shape)"
   ]
  },
  {
   "source": [
    "## Gated-GCN Layer\n",
    "\n",
    "To use the Gated-GCN layer from the *Bresson et al.* paper, the steps are different since the layer requires edge features as inputs, and outputs new edge features.\n",
    "\n",
    "<sub>Bresson, Xavier, and Thomas Laurent. \"Residual gated graph convnets.\" arXiv preprint arXiv:1711.07553 (2017).</sub>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GatedGCNLayer(5 -> 11, activation=relu)\ntorch.Size([7, 5])\ntorch.Size([7, 11])\ntorch.Size([14, 13])\ntorch.Size([14, 11])\n"
     ]
    }
   ],
   "source": [
    "# We first need to extract the node and edge features from the graph.\n",
    "graph = deepcopy(bg)\n",
    "h_in = graph.ndata[\"h\"]\n",
    "e_in = graph.edata[\"e\"]\n",
    "\n",
    "# We create the layer\n",
    "layer = GatedGCNLayer(\n",
    "        in_dim=in_dim, out_dim=out_dim, \n",
    "        in_dim_edges=in_dim_edges, out_dim_edges=out_dim,\n",
    "        activation=\"relu\", dropout=.3, normalization=\"batch_norm\").to(float)\n",
    "\n",
    "# We apply the forward loop on the node features\n",
    "h_out, e_out = layer(graph, h_in, e_in)\n",
    "\n",
    "# 7 is the number of nodes, 5 number of input features and 11 number of output features\n",
    "# 13 is the number of input edge features\n",
    "print(layer)\n",
    "print(h_in.shape)\n",
    "print(h_out.shape)\n",
    "print(e_in.shape)\n",
    "print(e_out.shape)"
   ]
  },
  {
   "source": [
    "# PNA\n",
    "\n",
    "PNA is a multi-aggregator method proposed by *Corso et al.*. It supports 2 types of aggregations, convolutional *PNA-conv* or message passing *PNA-msgpass*.\n",
    "\n",
    "<sub>PNA: Principal Neighbourhood Aggregation \n",
    "Gabriele Corso, Luca Cavalleri, Dominique Beaini, Pietro Lio, Petar Velickovic\n",
    "https://arxiv.org/abs/2004.05718</sub>\n",
    "\n",
    "## PNA-conv\n",
    "\n",
    "First, let's focus on the PNA-conv. In this case, it works exactly as the GCN and GIN methods. Although not presented in the example, PNA-conv also supports edge features by concatenating them to the node features during convolution."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PNAConvolutionalLayer(5 -> 11, activation=relu)\ntorch.Size([7, 5])\ntorch.Size([7, 11])\n"
     ]
    }
   ],
   "source": [
    "graph = deepcopy(bg)\n",
    "h_in = graph.ndata[\"h\"]\n",
    "\n",
    "# We create the layer, and need to specify the aggregators and scalers\n",
    "layer = PNAConvolutionalLayer(\n",
    "    in_dim=in_dim, out_dim=out_dim, \n",
    "    aggregators=[\"mean\", \"max\", \"min\", \"std\"],\n",
    "    scalers=[\"identity\", \"amplification\", \"attenuation\"],\n",
    "    activation=\"relu\", dropout=.3, normalization=\"batch_norm\").to(float)\n",
    "\n",
    "h_out = layer(graph, h_in)\n",
    "\n",
    "print(layer)\n",
    "print(h_in.shape)\n",
    "print(h_out.shape)"
   ]
  },
  {
   "source": [
    "## PNA-msgpass\n",
    "\n",
    "The PNA message passing is typically more powerful that the convolutional one, and it supports edges as inputs, but doesn't output edges. It's usage is very similar to the *PNA-conv*. Here, we also present the option to specify the edge dimensions and features."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PNAMessagePassingLayer(5 -> 11, activation=relu)\ntorch.Size([7, 5])\ntorch.Size([7, 11])\n"
     ]
    }
   ],
   "source": [
    "graph = deepcopy(bg)\n",
    "h_in = graph.ndata[\"h\"]\n",
    "e_in = graph.edata[\"e\"]\n",
    "\n",
    "# We create the layer, and need to specify the aggregators and scalers\n",
    "layer = PNAMessagePassingLayer(\n",
    "    in_dim=in_dim, out_dim=out_dim, in_dim_edges=in_dim_edges,\n",
    "    aggregators=[\"mean\", \"max\", \"min\", \"std\"],\n",
    "    scalers=[\"identity\", \"amplification\", \"attenuation\"],\n",
    "    activation=\"relu\", dropout=.3, normalization=\"batch_norm\").to(float)\n",
    "\n",
    "h_out = layer(graph, h_in, e_in)\n",
    "\n",
    "print(layer)\n",
    "print(h_in.shape)\n",
    "print(h_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
