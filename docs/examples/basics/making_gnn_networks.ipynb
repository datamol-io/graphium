{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making GNN Networks\n",
    "\n",
    "In this example, you will learn how to easily build a full GNN network using any kind of GNN layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import dgl\n",
    "from copy import deepcopy\n",
    "\n",
    "from goli.nn.dgl_layers import PNAMessagePassingLayer\n",
    "from goli.nn.architectures import FullDGLNetwork\n",
    "\n",
    "_ = torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first create some simple batched graphs that will be used accross the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=7, num_edges=14,\n",
      "      ndata_schemes={'h': Scheme(shape=(5,), dtype=torch.float64)}\n",
      "      edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float64)})\n"
     ]
    }
   ],
   "source": [
    "in_dim = 5          # Input node-feature dimensions\n",
    "out_dim = 11        # Desired output node-feature dimensions\n",
    "in_dim_edges = 13   # Input edge-feature dimensions\n",
    "\n",
    "# Let's create 2 simple graphs. Here the tensors represent the connectivity between nodes\n",
    "g1 = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])))\n",
    "g2 = dgl.graph((torch.tensor([0, 0, 0, 1]), torch.tensor([0, 1, 2, 0])))\n",
    "\n",
    "# We add some node features to the graphs\n",
    "g1.ndata[\"h\"] = torch.rand(g1.num_nodes(), in_dim, dtype=float)\n",
    "g2.ndata[\"h\"] = torch.rand(g2.num_nodes(), in_dim, dtype=float)\n",
    "\n",
    "# We also add some edge features to the graphs\n",
    "g1.edata[\"e\"] = torch.rand(g1.num_edges(), in_dim_edges, dtype=float)\n",
    "g2.edata[\"e\"] = torch.rand(g2.num_edges(), in_dim_edges, dtype=float)\n",
    "\n",
    "# Finally we batch the graphs in a way compatible with the DGL library\n",
    "bg = dgl.batch([g1, g2])\n",
    "bg = dgl.add_self_loop(bg)\n",
    "\n",
    "# The batched graph will show as a single graph with 7 nodes\n",
    "print(bg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "To build the network, we must define the arguments to pass at the different steps:\n",
    "\n",
    "- `pre_nn_kwargs`: The parameters used by a feed-forward neural network on the input node-features, before passing to the convolutional layers. See class `FeedForwardNN` for details on the required parameters. Will be ignored if set to `None`.\n",
    "\n",
    "- `gnn_kwargs`: The parameters used by a feed-forward **graph** neural network on the features after it has passed through the pre-processing neural network. See class `FeedForwardDGL` for details on the required parameters.\n",
    "\n",
    "- `post_nn_kwargs`: The parameters used by a feed-forward neural network on the features after the GNN layers. See class `FeedForwardNN` for details on the required parameters. Will be ignored if set to `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dim_1 = 23\n",
    "temp_dim_2 = 17\n",
    "\n",
    "pre_nn_kwargs = {\n",
    "        \"in_dim\": in_dim,\n",
    "        \"out_dim\": temp_dim_1,\n",
    "        \"hidden_dims\": [4, 4, 4],\n",
    "        \"activation\": \"relu\",\n",
    "        \"last_activation\": \"none\",\n",
    "        \"batch_norm\": True,\n",
    "        \"dropout\": 0.2,    }\n",
    "\n",
    "post_nn_kwargs = {\n",
    "        \"in_dim\": temp_dim_2,\n",
    "        \"out_dim\": out_dim,\n",
    "        \"hidden_dims\": [6, 6],\n",
    "        \"activation\": \"relu\",\n",
    "        \"last_activation\": \"sigmoid\",\n",
    "        \"batch_norm\": False,\n",
    "        \"dropout\": 0.,    }\n",
    "\n",
    "layer_kwargs = {\n",
    "    \"aggregators\": [\"mean\", \"max\", \"sum\"], \n",
    "    \"scalers\": [\"identity\", \"amplification\"],\n",
    "    \"in_dim_edges\": in_dim_edges}\n",
    "\n",
    "gnn_kwargs = {\n",
    "    \"in_dim\": temp_dim_1,\n",
    "    \"out_dim\": temp_dim_2,\n",
    "    \"hidden_dims\": [5, 5, 5, 5, 5, 5],\n",
    "    \"residual_type\": \"densenet\",\n",
    "    \"residual_skip_steps\": 2,\n",
    "    \"layer_type\": PNAMessagePassingLayer,\n",
    "    \"pooling\": [\"sum\"],\n",
    "    \"activation\": \"relu\",\n",
    "    \"last_activation\": \"none\",\n",
    "    \"batch_norm\": False,\n",
    "    \"dropout\": 0.2,\n",
    "    **layer_kwargs,\n",
    "}\n",
    "\n",
    "gnn_net = FullDGLNetwork(\n",
    "    pre_nn_kwargs=pre_nn_kwargs, \n",
    "    gnn_kwargs=gnn_kwargs, \n",
    "    post_nn_kwargs=post_nn_kwargs).to(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the network\n",
    "\n",
    "Once the network is defined, we only need to run the forward pass on the input graphs to get a prediction.\n",
    "\n",
    "The network will handle the node and edge features depending on it's parameters and layer type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 5])\n",
      "torch.Size([1, 11])\n",
      "\n",
      "\n",
      "DGL_GNN\n",
      "---------\n",
      "    pre-trans-NN(depth=4, ResidualConnectionNone(skip_steps=1))\n",
      "        [FCLayer[5 -> 4 -> 4 -> 4 -> 23] -> Linear({self.out_dim})\n",
      "    \n",
      "    main-GNN(depth=7, ResidualConnectionDenseNet(skip_steps=2))\n",
      "        PNAMessagePassingLayer[23 -> 5 -> 5 -> 5 -> 5 -> 5 -> 5 -> 17]\n",
      "        -> Pooling(['sum']) -> FCLayer(17 -> 17, activation=None)\n",
      "    \n",
      "    post-trans-NN(depth=3, ResidualConnectionNone(skip_steps=1))\n",
      "        [FCLayer[17 -> 6 -> 6 -> 11] -> Linear({self.out_dim})\n"
     ]
    }
   ],
   "source": [
    "graph = deepcopy(bg)\n",
    "h_in = graph.ndata[\"h\"]\n",
    "\n",
    "h_out = gnn_net(graph)\n",
    "\n",
    "print(h_in.shape)\n",
    "print(h_out.shape)\n",
    "print(\"\\n\")\n",
    "print(gnn_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:goli]",
   "language": "python",
   "name": "conda-env-goli-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
