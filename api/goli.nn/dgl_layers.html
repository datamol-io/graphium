
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A deep learning library focused on graph representation learning for real-world chemical tasks.">
      
      
      
        <link rel="canonical" href="https://github.com/valence-discovery/goli/api/goli.nn/dgl_layers.html">
      
      
        <link rel="prev" href="pyg_layers.html">
      
      
        <link rel="next" href="../goli.features.html">
      
      <link rel="icon" href="../../images/logo.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.1.3">
    
    
      
        <title>goli.nn.dgl_layers - goli</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.c4a75a56.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.a0c5b2b5.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../_assets/css/custom.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="indigo">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#goli.nn.dgl_layers.dgn_dgl" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../index.html" title="goli" class="md-header__button md-logo" aria-label="goli" data-md-component="logo">
      
  <img src="../../images/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            goli
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              goli.nn.dgl_layers
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/valence-discovery/goli" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    valence-discovery/goli
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../index.html" title="goli" class="md-nav__button md-logo" aria-label="goli" data-md-component="logo">
      
  <img src="../../images/logo.png" alt="logo">

    </a>
    goli
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/valence-discovery/goli" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.3.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    valence-discovery/goli
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../index.html" class="md-nav__link">
        Overview
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
      
      
      
        <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
          Tutorials
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Tutorials
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_1" >
      
      
      
        <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
          basics
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_1">
          <span class="md-nav__icon md-icon"></span>
          basics
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/basics/using_gnn_layers.html" class="md-nav__link">
        Using GNN layers
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/basics/implementing_gnn_layers.html" class="md-nav__link">
        Creating GNN layers
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/basics/making_gnn_networks.html" class="md-nav__link">
        Making GNN Networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/basics/csv_to_parquet.html" class="md-nav__link">
        Convert CSV to Parquet files
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/basics/parquet_reader.html" class="md-nav__link">
        Reading Parquet files
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2" >
      
      
      
        <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
          model_training
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_2">
          <span class="md-nav__icon md-icon"></span>
          model_training
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/model_training/simple-molecular-model.html" class="md-nav__link">
        Building and training a simple model from configurations
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/model_training/ipu_training.html" class="md-nav__link">
        Building and training on IPU from configurations
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/basics/choosing_parallelization.ipynb" class="md-nav__link">
        Chosing the right parallelization
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../design.html" class="md-nav__link">
        Design
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../datasets.html" class="md-nav__link">
        Datasets
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../pretrained_models.html" class="md-nav__link">
        Pretrained Models
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../contribute.html" class="md-nav__link">
        Contribute
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../license.html" class="md-nav__link">
        License
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" checked>
      
      
      
        <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
          API
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_8">
          <span class="md-nav__icon md-icon"></span>
          API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_1" checked>
      
      
      
        <label class="md-nav__link" for="__nav_8_1" id="__nav_8_1_label" tabindex="0">
          goli.nn
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_1_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_8_1">
          <span class="md-nav__icon md-icon"></span>
          goli.nn
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="goli.nn.html" class="md-nav__link">
        goli.nn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="architectures.html" class="md-nav__link">
        goli.nn.architectures
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="encoders.html" class="md-nav__link">
        goli.nn.encoders
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="pyg_layers.html" class="md-nav__link">
        goli.nn.pyg_layers
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          goli.nn.dgl_layers
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="dgl_layers.html" class="md-nav__link md-nav__link--active">
        goli.nn.dgl_layers
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_dgl" class="md-nav__link">
    dgn_dgl
  </a>
  
    <nav class="md-nav" aria-label="dgn_dgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_dgl.BaseDGNDgl" class="md-nav__link">
    BaseDGNDgl
  </a>
  
    <nav class="md-nav" aria-label="BaseDGNDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_dgl.BaseDGNDgl.message_func" class="md-nav__link">
    message_func()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_dgl.BaseDGNDgl.parse_aggregators" class="md-nav__link">
    parse_aggregators()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_dgl.BaseDGNDgl.reduce_func" class="md-nav__link">
    reduce_func()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_dgl.DGNConvolutionalDgl" class="md-nav__link">
    DGNConvolutionalDgl
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_dgl.DGNMessagePassingDgl" class="md-nav__link">
    DGNMessagePassingDgl
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_operations" class="md-nav__link">
    dgn_operations
  </a>
  
    <nav class="md-nav" aria-label="dgn_operations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_operations.aggregate_dir_backward" class="md-nav__link">
    aggregate_dir_backward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_operations.aggregate_dir_dx_abs" class="md-nav__link">
    aggregate_dir_dx_abs()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_operations.aggregate_dir_dx_abs_balanced" class="md-nav__link">
    aggregate_dir_dx_abs_balanced()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_operations.aggregate_dir_dx_no_abs" class="md-nav__link">
    aggregate_dir_dx_no_abs()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_operations.aggregate_dir_forward" class="md-nav__link">
    aggregate_dir_forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_operations.aggregate_dir_smooth" class="md-nav__link">
    aggregate_dir_smooth()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_operations.get_grad_of_pos" class="md-nav__link">
    get_grad_of_pos()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gat_dgl" class="md-nav__link">
    gat_dgl
  </a>
  
    <nav class="md-nav" aria-label="gat_dgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gat_dgl.GATDgl" class="md-nav__link">
    GATDgl
  </a>
  
    <nav class="md-nav" aria-label="GATDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gat_dgl.GATDgl.layer_inputs_edges" class="md-nav__link">
    layer_inputs_edges
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gat_dgl.GATDgl.layer_outputs_edges" class="md-nav__link">
    layer_outputs_edges
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gat_dgl.GATDgl.out_dim_factor" class="md-nav__link">
    out_dim_factor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gat_dgl.GATDgl.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gat_dgl.GATDgl.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gat_dgl.GATDgl.layer_supports_edges" class="md-nav__link">
    layer_supports_edges()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gated_gcn_dgl" class="md-nav__link">
    gated_gcn_dgl
  </a>
  
    <nav class="md-nav" aria-label="gated_gcn_dgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl" class="md-nav__link">
    GatedGCNDgl
  </a>
  
    <nav class="md-nav" aria-label="GatedGCNDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.layer_inputs_edges" class="md-nav__link">
    layer_inputs_edges
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.layer_outputs_edges" class="md-nav__link">
    layer_outputs_edges
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.out_dim_factor" class="md-nav__link">
    out_dim_factor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.layer_supports_edges" class="md-nav__link">
    layer_supports_edges()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gcn_dgl" class="md-nav__link">
    gcn_dgl
  </a>
  
    <nav class="md-nav" aria-label="gcn_dgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gcn_dgl.GCNDgl" class="md-nav__link">
    GCNDgl
  </a>
  
    <nav class="md-nav" aria-label="GCNDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gcn_dgl.GCNDgl.layer_inputs_edges" class="md-nav__link">
    layer_inputs_edges
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gcn_dgl.GCNDgl.layer_outputs_edges" class="md-nav__link">
    layer_outputs_edges
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gcn_dgl.GCNDgl.out_dim_factor" class="md-nav__link">
    out_dim_factor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gcn_dgl.GCNDgl.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gcn_dgl.GCNDgl.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gcn_dgl.GCNDgl.layer_supports_edges" class="md-nav__link">
    layer_supports_edges()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gin_dgl" class="md-nav__link">
    gin_dgl
  </a>
  
    <nav class="md-nav" aria-label="gin_dgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gin_dgl.GINDgl" class="md-nav__link">
    GINDgl
  </a>
  
    <nav class="md-nav" aria-label="GINDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gin_dgl.GINDgl.layer_inputs_edges" class="md-nav__link">
    layer_inputs_edges
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gin_dgl.GINDgl.layer_outputs_edges" class="md-nav__link">
    layer_outputs_edges
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gin_dgl.GINDgl.out_dim_factor" class="md-nav__link">
    out_dim_factor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gin_dgl.GINDgl.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gin_dgl.GINDgl.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gin_dgl.GINDgl.layer_supports_edges" class="md-nav__link">
    layer_supports_edges()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gin_dgl.GINDgl.message_func" class="md-nav__link">
    message_func()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl" class="md-nav__link">
    pna_dgl
  </a>
  
    <nav class="md-nav" aria-label="pna_dgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl" class="md-nav__link">
    BasePNADgl
  </a>
  
    <nav class="md-nav" aria-label="BasePNADgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.layer_inputs_edges" class="md-nav__link">
    layer_inputs_edges
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.layer_outputs_edges" class="md-nav__link">
    layer_outputs_edges
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.out_dim_factor" class="md-nav__link">
    out_dim_factor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.add_virtual_graph_if_no_edges" class="md-nav__link">
    add_virtual_graph_if_no_edges()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.layer_supports_edges" class="md-nav__link">
    layer_supports_edges()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.message_func" class="md-nav__link">
    message_func()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.reduce_func" class="md-nav__link">
    reduce_func()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.remove_virtual_graph_if_no_edges" class="md-nav__link">
    remove_virtual_graph_if_no_edges()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.PNAConvolutionalDgl" class="md-nav__link">
    PNAConvolutionalDgl
  </a>
  
    <nav class="md-nav" aria-label="PNAConvolutionalDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.PNAConvolutionalDgl.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.PNAConvolutionalDgl.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.PNAConvolutionalDgl.pretrans_edges" class="md-nav__link">
    pretrans_edges()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.PNAMessagePassingDgl" class="md-nav__link">
    PNAMessagePassingDgl
  </a>
  
    <nav class="md-nav" aria-label="PNAMessagePassingDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.PNAMessagePassingDgl.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.PNAMessagePassingDgl.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.PNAMessagePassingDgl.layer_supports_edges" class="md-nav__link">
    layer_supports_edges()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.PNAMessagePassingDgl.pretrans_edges" class="md-nav__link">
    pretrans_edges()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_operations" class="md-nav__link">
    pna_operations
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl" class="md-nav__link">
    pooling_dgl
  </a>
  
    <nav class="md-nav" aria-label="pooling_dgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.DirPoolingDgl" class="md-nav__link">
    DirPoolingDgl
  </a>
  
    <nav class="md-nav" aria-label="DirPoolingDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.DirPoolingDgl.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.LogSumPoolingDgl" class="md-nav__link">
    LogSumPoolingDgl
  </a>
  
    <nav class="md-nav" aria-label="LogSumPoolingDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.LogSumPoolingDgl.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.MinPoolingDgl" class="md-nav__link">
    MinPoolingDgl
  </a>
  
    <nav class="md-nav" aria-label="MinPoolingDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.MinPoolingDgl.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.S2SReadoutDgl" class="md-nav__link">
    S2SReadoutDgl
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.StdPoolingDgl" class="md-nav__link">
    StdPoolingDgl
  </a>
  
    <nav class="md-nav" aria-label="StdPoolingDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.StdPoolingDgl.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.VirtualNodeDgl" class="md-nav__link">
    VirtualNodeDgl
  </a>
  
    <nav class="md-nav" aria-label="VirtualNodeDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.VirtualNodeDgl.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.VirtualNodeDgl.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.parse_pooling_layer_dgl" class="md-nav__link">
    parse_pooling_layer_dgl()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../goli.features.html" class="md-nav__link">
        goli.features
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../goli.trainer.html" class="md-nav__link">
        goli.trainer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../goli.data.html" class="md-nav__link">
        goli.data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../goli.utils.html" class="md-nav__link">
        goli.utils
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../goli.config.html" class="md-nav__link">
        goli.config
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../goli.ipu.html" class="md-nav__link">
        goli.ipu
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../goli.visualization.html" class="md-nav__link">
        goli.visualization
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../cli_references.html" class="md-nav__link">
        CLI
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_dgl" class="md-nav__link">
    dgn_dgl
  </a>
  
    <nav class="md-nav" aria-label="dgn_dgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_dgl.BaseDGNDgl" class="md-nav__link">
    BaseDGNDgl
  </a>
  
    <nav class="md-nav" aria-label="BaseDGNDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_dgl.BaseDGNDgl.message_func" class="md-nav__link">
    message_func()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_dgl.BaseDGNDgl.parse_aggregators" class="md-nav__link">
    parse_aggregators()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_dgl.BaseDGNDgl.reduce_func" class="md-nav__link">
    reduce_func()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_dgl.DGNConvolutionalDgl" class="md-nav__link">
    DGNConvolutionalDgl
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_dgl.DGNMessagePassingDgl" class="md-nav__link">
    DGNMessagePassingDgl
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_operations" class="md-nav__link">
    dgn_operations
  </a>
  
    <nav class="md-nav" aria-label="dgn_operations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_operations.aggregate_dir_backward" class="md-nav__link">
    aggregate_dir_backward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_operations.aggregate_dir_dx_abs" class="md-nav__link">
    aggregate_dir_dx_abs()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_operations.aggregate_dir_dx_abs_balanced" class="md-nav__link">
    aggregate_dir_dx_abs_balanced()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_operations.aggregate_dir_dx_no_abs" class="md-nav__link">
    aggregate_dir_dx_no_abs()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_operations.aggregate_dir_forward" class="md-nav__link">
    aggregate_dir_forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_operations.aggregate_dir_smooth" class="md-nav__link">
    aggregate_dir_smooth()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.dgn_operations.get_grad_of_pos" class="md-nav__link">
    get_grad_of_pos()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gat_dgl" class="md-nav__link">
    gat_dgl
  </a>
  
    <nav class="md-nav" aria-label="gat_dgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gat_dgl.GATDgl" class="md-nav__link">
    GATDgl
  </a>
  
    <nav class="md-nav" aria-label="GATDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gat_dgl.GATDgl.layer_inputs_edges" class="md-nav__link">
    layer_inputs_edges
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gat_dgl.GATDgl.layer_outputs_edges" class="md-nav__link">
    layer_outputs_edges
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gat_dgl.GATDgl.out_dim_factor" class="md-nav__link">
    out_dim_factor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gat_dgl.GATDgl.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gat_dgl.GATDgl.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gat_dgl.GATDgl.layer_supports_edges" class="md-nav__link">
    layer_supports_edges()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gated_gcn_dgl" class="md-nav__link">
    gated_gcn_dgl
  </a>
  
    <nav class="md-nav" aria-label="gated_gcn_dgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl" class="md-nav__link">
    GatedGCNDgl
  </a>
  
    <nav class="md-nav" aria-label="GatedGCNDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.layer_inputs_edges" class="md-nav__link">
    layer_inputs_edges
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.layer_outputs_edges" class="md-nav__link">
    layer_outputs_edges
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.out_dim_factor" class="md-nav__link">
    out_dim_factor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.layer_supports_edges" class="md-nav__link">
    layer_supports_edges()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gcn_dgl" class="md-nav__link">
    gcn_dgl
  </a>
  
    <nav class="md-nav" aria-label="gcn_dgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gcn_dgl.GCNDgl" class="md-nav__link">
    GCNDgl
  </a>
  
    <nav class="md-nav" aria-label="GCNDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gcn_dgl.GCNDgl.layer_inputs_edges" class="md-nav__link">
    layer_inputs_edges
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gcn_dgl.GCNDgl.layer_outputs_edges" class="md-nav__link">
    layer_outputs_edges
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gcn_dgl.GCNDgl.out_dim_factor" class="md-nav__link">
    out_dim_factor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gcn_dgl.GCNDgl.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gcn_dgl.GCNDgl.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gcn_dgl.GCNDgl.layer_supports_edges" class="md-nav__link">
    layer_supports_edges()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gin_dgl" class="md-nav__link">
    gin_dgl
  </a>
  
    <nav class="md-nav" aria-label="gin_dgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gin_dgl.GINDgl" class="md-nav__link">
    GINDgl
  </a>
  
    <nav class="md-nav" aria-label="GINDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gin_dgl.GINDgl.layer_inputs_edges" class="md-nav__link">
    layer_inputs_edges
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gin_dgl.GINDgl.layer_outputs_edges" class="md-nav__link">
    layer_outputs_edges
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gin_dgl.GINDgl.out_dim_factor" class="md-nav__link">
    out_dim_factor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gin_dgl.GINDgl.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gin_dgl.GINDgl.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gin_dgl.GINDgl.layer_supports_edges" class="md-nav__link">
    layer_supports_edges()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.gin_dgl.GINDgl.message_func" class="md-nav__link">
    message_func()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl" class="md-nav__link">
    pna_dgl
  </a>
  
    <nav class="md-nav" aria-label="pna_dgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl" class="md-nav__link">
    BasePNADgl
  </a>
  
    <nav class="md-nav" aria-label="BasePNADgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.layer_inputs_edges" class="md-nav__link">
    layer_inputs_edges
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.layer_outputs_edges" class="md-nav__link">
    layer_outputs_edges
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.out_dim_factor" class="md-nav__link">
    out_dim_factor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.add_virtual_graph_if_no_edges" class="md-nav__link">
    add_virtual_graph_if_no_edges()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.layer_supports_edges" class="md-nav__link">
    layer_supports_edges()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.message_func" class="md-nav__link">
    message_func()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.reduce_func" class="md-nav__link">
    reduce_func()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.remove_virtual_graph_if_no_edges" class="md-nav__link">
    remove_virtual_graph_if_no_edges()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.PNAConvolutionalDgl" class="md-nav__link">
    PNAConvolutionalDgl
  </a>
  
    <nav class="md-nav" aria-label="PNAConvolutionalDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.PNAConvolutionalDgl.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.PNAConvolutionalDgl.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.PNAConvolutionalDgl.pretrans_edges" class="md-nav__link">
    pretrans_edges()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.PNAMessagePassingDgl" class="md-nav__link">
    PNAMessagePassingDgl
  </a>
  
    <nav class="md-nav" aria-label="PNAMessagePassingDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.PNAMessagePassingDgl.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.PNAMessagePassingDgl.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.PNAMessagePassingDgl.layer_supports_edges" class="md-nav__link">
    layer_supports_edges()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_dgl.PNAMessagePassingDgl.pretrans_edges" class="md-nav__link">
    pretrans_edges()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pna_operations" class="md-nav__link">
    pna_operations
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl" class="md-nav__link">
    pooling_dgl
  </a>
  
    <nav class="md-nav" aria-label="pooling_dgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.DirPoolingDgl" class="md-nav__link">
    DirPoolingDgl
  </a>
  
    <nav class="md-nav" aria-label="DirPoolingDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.DirPoolingDgl.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.LogSumPoolingDgl" class="md-nav__link">
    LogSumPoolingDgl
  </a>
  
    <nav class="md-nav" aria-label="LogSumPoolingDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.LogSumPoolingDgl.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.MinPoolingDgl" class="md-nav__link">
    MinPoolingDgl
  </a>
  
    <nav class="md-nav" aria-label="MinPoolingDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.MinPoolingDgl.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.S2SReadoutDgl" class="md-nav__link">
    S2SReadoutDgl
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.StdPoolingDgl" class="md-nav__link">
    StdPoolingDgl
  </a>
  
    <nav class="md-nav" aria-label="StdPoolingDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.StdPoolingDgl.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.VirtualNodeDgl" class="md-nav__link">
    VirtualNodeDgl
  </a>
  
    <nav class="md-nav" aria-label="VirtualNodeDgl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.VirtualNodeDgl.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.VirtualNodeDgl.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goli.nn.dgl_layers.pooling_dgl.parse_pooling_layer_dgl" class="md-nav__link">
    parse_pooling_layer_dgl()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>goli.nn.dgl_layers</h1>

<div class="doc doc-object doc-module">



<h3 id="goli.nn.dgl_layers.dgn_dgl" class="doc doc-heading">
          <code>goli.nn.dgl_layers.dgn_dgl</code>


<a href="#goli.nn.dgl_layers.dgn_dgl" class="headerlink" title="Permanent link">&para;</a></h3>

  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="goli.nn.dgl_layers.dgn_dgl.BaseDGNDgl" class="doc doc-heading">
        <code>BaseDGNDgl</code>


<a href="#goli.nn.dgl_layers.dgn_dgl.BaseDGNDgl" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">




  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.dgn_dgl.BaseDGNDgl.message_func" class="doc doc-heading">
<code class="highlight language-python"><span class="n">message_func</span><span class="p">(</span><span class="n">edges</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.dgn_dgl.BaseDGNDgl.message_func" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>The message function to generate messages along the edges.</p>

  </div>

</div>

<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.dgn_dgl.BaseDGNDgl.parse_aggregators" class="doc doc-heading">
<code class="highlight language-python"><span class="n">parse_aggregators</span><span class="p">(</span><span class="n">aggregators_name</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.dgn_dgl.BaseDGNDgl.parse_aggregators" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Parse the aggregators from a list of strings into a list of callables.</p>
<p>The possibilities are:</p>
<ul>
<li><code>"mean"</code></li>
<li><code>"sum"</code></li>
<li><code>"min"</code></li>
<li><code>"max"</code></li>
<li><code>"std"</code></li>
<li><code>"dir{dir_idx:int}/smooth/{Optional[temperature:float]}"</code></li>
<li><code>"dir{dir_idx:int}/dx_abs/{Optional[temperature:float]}"</code></li>
<li><code>"dir{dir_idx:int}/dx_no_abs/{Optional[temperature:float]}"</code></li>
<li><code>"dir{dir_idx:int}/dx_abs_balanced/{Optional[temperature:float]}"</code></li>
<li><code>"dir{dir_idx:int}/forward/{Optional[temperature:float]}"</code></li>
<li><code>"dir{dir_idx:int}/backward/{Optional[temperature:float]}"</code></li>
</ul>
<p><code>dir_idx</code> is an integer specifying the index of the positional encoding
to use for direction. In the case of eigenvector-based directions, <code>dir_idx=1</code>
is chosen for the first non-trivial eigenvector and <code>dir_idx=2</code> for the second.</p>
<p><code>temperature</code> is used to harden the direction using a softmax on the directional
matrices. If it is not provided, then no softmax is applied. The larger the temperature,
the more weight is attributed to the dominant direction.</p>
<p>The graph. Must have the key <code>graph.ndata["pos_dir"]</code></p>

<details class="example">
  <summary>Example</summary>
  <div class="highlight"><pre><span></span><code>In:     self.parse_aggregators([&quot;dir1/dx_abs&quot;, &quot;dir2/smooth/0.2&quot;])
Out:    [partial(aggregate_dir_dx_abs, dir_idx=1, temperature=None),
         partial(aggregate_dir_smooth, dir_idx=2, temperature=0.2)]
</code></pre></div>
</details>
  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>aggregators_name</code></td>
          <td>
                <code><span title="typing.List">List</span>[str]</code>
          </td>
          <td><p>The list of all aggregators names to use, selected
from the list of possible strings.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>aggregators</code></td>          <td>
                <code><span title="typing.List">List</span>[<span title="typing.Callable">Callable</span>]</code>
          </td>
          <td><p>The list of all callable aggregators.</p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.dgn_dgl.BaseDGNDgl.reduce_func" class="doc doc-heading">
<code class="highlight language-python"><span class="n">reduce_func</span><span class="p">(</span><span class="n">nodes</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.dgn_dgl.BaseDGNDgl.reduce_func" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>The reduce function to aggregate the messages.
Apply the aggregators and scalers, and concatenate the results.</p>

  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="goli.nn.dgl_layers.dgn_dgl.DGNConvolutionalDgl" class="doc doc-heading">
        <code>DGNConvolutionalDgl</code>


<a href="#goli.nn.dgl_layers.dgn_dgl.DGNConvolutionalDgl" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><a class="autorefs autorefs-internal" title="goli.nn.dgl_layers.dgn_dgl.BaseDGNDgl" href="#goli.nn.dgl_layers.dgn_dgl.BaseDGNDgl">BaseDGNDgl</a></code>, <code><a class="autorefs autorefs-internal" title="goli.nn.dgl_layers.pna_dgl.PNAConvolutionalDgl" href="#goli.nn.dgl_layers.pna_dgl.PNAConvolutionalDgl">PNAConvolutionalDgl</a></code></p>

  
      <p>Implementation of the convolutional architecture of the DGN layer,
previously known as <code>DGNSimpleLayer</code>. This layer aggregates the
neighbouring messages using multiple aggregators and scalers,
concatenates their results, then applies an MLP on the concatenated
features.</p>
<p>The graph. Must have the key <code>graph.ndata["pos_dir"]</code></p>
<p>DGN: Directional Graph Networks
Dominique Beaini, Saro Passaro, Vincent Ltourneau, William L. Hamilton, Gabriele Corso, Pietro Li
<a href="https://arxiv.org/pdf/2010.02863.pdf">https://arxiv.org/pdf/2010.02863.pdf</a></p>



  

  <div class="doc doc-children">











  </div>

  </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="goli.nn.dgl_layers.dgn_dgl.DGNMessagePassingDgl" class="doc doc-heading">
        <code>DGNMessagePassingDgl</code>


<a href="#goli.nn.dgl_layers.dgn_dgl.DGNMessagePassingDgl" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><a class="autorefs autorefs-internal" title="goli.nn.dgl_layers.dgn_dgl.BaseDGNDgl" href="#goli.nn.dgl_layers.dgn_dgl.BaseDGNDgl">BaseDGNDgl</a></code>, <code><a class="autorefs autorefs-internal" title="goli.nn.dgl_layers.pna_dgl.PNAMessagePassingDgl" href="#goli.nn.dgl_layers.pna_dgl.PNAMessagePassingDgl">PNAMessagePassingDgl</a></code></p>

  
      <p>Implementation of the message passing architecture of the DGN message passing layer,
previously known as <code>DGNLayerComplex</code>. This layer applies an MLP as
pretransformation to the concatenation of <span class="arithmatex">\([h_u, h_v, e_{uv}]\)</span> to generate
the messages, with <span class="arithmatex">\(h_u\)</span> the node feature, <span class="arithmatex">\(h_v\)</span> the neighbour node features,
and <span class="arithmatex">\(e_{uv}\)</span> the edge feature between the nodes <span class="arithmatex">\(u\)</span> and <span class="arithmatex">\(v\)</span>.</p>
<p>After the pre-transformation, it aggregates the messages using
multiple aggregators and scalers,
concatenates their results, then applies an MLP on the concatenated
features.</p>
<p>The graph. Must have the key <code>graph.ndata["pos_dir"]</code></p>
<p>DGN: Directional Graph Networks
Dominique Beaini, Saro Passaro, Vincent Ltourneau, William L. Hamilton, Gabriele Corso, Pietro Li
<a href="https://arxiv.org/pdf/2010.02863.pdf">https://arxiv.org/pdf/2010.02863.pdf</a></p>



  

  <div class="doc doc-children">











  </div>

  </div>

</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="goli.nn.dgl_layers.dgn_operations" class="doc doc-heading">
          <code>goli.nn.dgl_layers.dgn_operations</code>


<a href="#goli.nn.dgl_layers.dgn_operations" class="headerlink" title="Permanent link">&para;</a></h3>

  <div class="doc doc-contents first">

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h4 id="goli.nn.dgl_layers.dgn_operations.aggregate_dir_backward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">aggregate_dir_backward</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">source_pos</span><span class="p">,</span> <span class="n">dest_pos</span><span class="p">,</span> <span class="n">h_in</span><span class="p">,</span> <span class="n">dir_idx</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.dgn_operations.aggregate_dir_backward" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">
  
      <p>The aggregation is the following:</p>
<div class="arithmatex">\[y^{(l)} = \hat{F}^-_k h^{(l)}\]</div>
<ul>
<li><span class="arithmatex">\(\hat{F}^-_k\)</span> is the normalized positive component of the directional field <em>k-th</em> directional field <span class="arithmatex">\(F_k\)</span></li>
<li><span class="arithmatex">\(y^{(l)}\)</span> is the returned aggregated result at the <em>l-th</em> layer.</li>
<li><span class="arithmatex">\(h^{(l)}\)</span> is the node features at the <em>l-th</em> layer.</li>
</ul>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>h</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The features to aggregate <span class="arithmatex">\(h^{(l)}\)</span></p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>source_pos</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The positional encoding at the source node, used to compute the directional field</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>dest_pos</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The positional encoding at the destination node, used to compute the directional field</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>h_in</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The input features of the layer, before any operation.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>dir_idx</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>The index of the positional encoding (<span class="arithmatex">\(k\)</span> in the equation above)</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>temperature</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[float]</code>
          </td>
          <td><p>The temperature to use in the softmax of the directional field.
If <code>None</code>, then the softmax is not applied on the field</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>h_mod</code></td>          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The aggregated features <span class="arithmatex">\(y^{(l)}\)</span></p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="goli.nn.dgl_layers.dgn_operations.aggregate_dir_dx_abs" class="doc doc-heading">
<code class="highlight language-python"><span class="n">aggregate_dir_dx_abs</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">source_pos</span><span class="p">,</span> <span class="n">dest_pos</span><span class="p">,</span> <span class="n">h_in</span><span class="p">,</span> <span class="n">dir_idx</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.dgn_operations.aggregate_dir_dx_abs" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">
  
      <p>The aggregation is the following:</p>
<div class="arithmatex">\[y^{(l)} = |B_{dx}^k h^{(l)}|\]</div>
<div class="arithmatex">\[B_{dx}^k = \hat{F}_k - diag \left(\sum_j{\hat{F}_{k_{(:, j)}}} \right)\]</div>
<ul>
<li><span class="arithmatex">\(\hat{F}^+_k\)</span> is the normalized positive component of the directional field <em>k-th</em> directional field <span class="arithmatex">\(F_k\)</span></li>
<li><span class="arithmatex">\(y^{(l)}\)</span> is the returned aggregated result at the <em>l-th</em> layer.</li>
<li><span class="arithmatex">\(h^{(l)}\)</span> is the node features at the <em>l-th</em> layer.</li>
</ul>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>h</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The features to aggregate <span class="arithmatex">\(h^{(l)}\)</span></p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>source_pos</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The positional encoding at the source node, used to compute the directional field</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>dest_pos</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The positional encoding at the destination node, used to compute the directional field</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>h_in</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The input features of the layer, before any operation.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>dir_idx</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>The index of the positional encoding (<span class="arithmatex">\(k\)</span> in the equation above)</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>temperature</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[float]</code>
          </td>
          <td><p>The temperature to use in the softmax of the directional field.
If <code>None</code>, then the softmax is not applied on the field</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>h_mod</code></td>          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The aggregated features <span class="arithmatex">\(y^{(l)}\)</span></p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="goli.nn.dgl_layers.dgn_operations.aggregate_dir_dx_abs_balanced" class="doc doc-heading">
<code class="highlight language-python"><span class="n">aggregate_dir_dx_abs_balanced</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">source_pos</span><span class="p">,</span> <span class="n">dest_pos</span><span class="p">,</span> <span class="n">h_in</span><span class="p">,</span> <span class="n">dir_idx</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.dgn_operations.aggregate_dir_dx_abs_balanced" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">
  
      <p>The aggregation is the same as <code>aggregate_dir_dx_no_abs</code>, but the positive and
negative parts of the field are normalized separately.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>h</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The features to aggregate <span class="arithmatex">\(h^{(l)}\)</span></p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>source_pos</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The positional encoding at the source node, used to compute the directional field</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>dest_pos</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The positional encoding at the destination node, used to compute the directional field</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>h_in</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The input features of the layer, before any operation.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>dir_idx</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>The index of the positional encoding (<span class="arithmatex">\(k\)</span> in the equation above)</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>temperature</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[float]</code>
          </td>
          <td><p>The temperature to use in the softmax of the directional field.
If <code>None</code>, then the softmax is not applied on the field</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>h_mod</code></td>          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The aggregated features <span class="arithmatex">\(y^{(l)}\)</span></p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="goli.nn.dgl_layers.dgn_operations.aggregate_dir_dx_no_abs" class="doc doc-heading">
<code class="highlight language-python"><span class="n">aggregate_dir_dx_no_abs</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">source_pos</span><span class="p">,</span> <span class="n">dest_pos</span><span class="p">,</span> <span class="n">h_in</span><span class="p">,</span> <span class="n">dir_idx</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.dgn_operations.aggregate_dir_dx_no_abs" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">
  
      <p>The aggregation is the following:</p>
<div class="arithmatex">\[y^{(l)} = B_{dx}^k h^{(l)}\]</div>
<div class="arithmatex">\[B_{dx}^k = \hat{F}_k - diag \left(\sum_j{\hat{F}_{k_{(:, j)}}} \right)\]</div>
<ul>
<li><span class="arithmatex">\(\hat{F}^+_k\)</span> is the normalized positive component of the directional field <em>k-th</em> directional field <span class="arithmatex">\(F_k\)</span></li>
<li><span class="arithmatex">\(y^{(l)}\)</span> is the returned aggregated result at the <em>l-th</em> layer.</li>
<li><span class="arithmatex">\(h^{(l)}\)</span> is the node features at the <em>l-th</em> layer.</li>
</ul>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>h</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The features to aggregate <span class="arithmatex">\(h^{(l)}\)</span></p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>source_pos</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The positional encoding at the source node, used to compute the directional field</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>dest_pos</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The positional encoding at the destination node, used to compute the directional field</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>h_in</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The input features of the layer, before any operation.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>dir_idx</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>The index of the positional encoding (<span class="arithmatex">\(k\)</span> in the equation above)</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>temperature</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[float]</code>
          </td>
          <td><p>The temperature to use in the softmax of the directional field.
If <code>None</code>, then the softmax is not applied on the field</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>h_mod</code></td>          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The aggregated features <span class="arithmatex">\(y^{(l)}\)</span></p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="goli.nn.dgl_layers.dgn_operations.aggregate_dir_forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">aggregate_dir_forward</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">source_pos</span><span class="p">,</span> <span class="n">dest_pos</span><span class="p">,</span> <span class="n">h_in</span><span class="p">,</span> <span class="n">dir_idx</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.dgn_operations.aggregate_dir_forward" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">
  
      <p>The aggregation is the following:</p>
<div class="arithmatex">\[y^{(l)} = \hat{F}^+_k h^{(l)}\]</div>
<ul>
<li><span class="arithmatex">\(\hat{F}^+_k\)</span> is the normalized positive component of the directional field <em>k-th</em> directional field <span class="arithmatex">\(F_k\)</span></li>
<li><span class="arithmatex">\(y^{(l)}\)</span> is the returned aggregated result at the <em>l-th</em> layer.</li>
<li><span class="arithmatex">\(h^{(l)}\)</span> is the node features at the <em>l-th</em> layer.</li>
</ul>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>h</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The features to aggregate <span class="arithmatex">\(h^{(l)}\)</span></p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>source_pos</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The positional encoding at the source node, used to compute the directional field</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>dest_pos</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The positional encoding at the destination node, used to compute the directional field</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>h_in</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The input features of the layer, before any operation.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>dir_idx</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>The index of the positional encoding (<span class="arithmatex">\(k\)</span> in the equation above)</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>temperature</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[float]</code>
          </td>
          <td><p>The temperature to use in the softmax of the directional field.
If <code>None</code>, then the softmax is not applied on the field</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>h_mod</code></td>          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The aggregated features <span class="arithmatex">\(y^{(l)}\)</span></p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="goli.nn.dgl_layers.dgn_operations.aggregate_dir_smooth" class="doc doc-heading">
<code class="highlight language-python"><span class="n">aggregate_dir_smooth</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">source_pos</span><span class="p">,</span> <span class="n">dest_pos</span><span class="p">,</span> <span class="n">h_in</span><span class="p">,</span> <span class="n">dir_idx</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.dgn_operations.aggregate_dir_smooth" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">
  
      <p>The aggregation is the following:</p>
<div class="arithmatex">\[y^{(l)} = |\hat{F}_k| h^{(l)}\]</div>
<ul>
<li><span class="arithmatex">\(\hat{F}^+_k\)</span> is the normalized directional field <em>k-th</em> directional field <span class="arithmatex">\(F_k\)</span></li>
<li><span class="arithmatex">\(y^{(l)}\)</span> is the returned aggregated result at the <em>l-th</em> layer.</li>
<li><span class="arithmatex">\(h^{(l)}\)</span> is the node features at the <em>l-th</em> layer.</li>
</ul>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>h</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The features to aggregate <span class="arithmatex">\(h^{(l)}\)</span></p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>source_pos</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The positional encoding at the source node, used to compute the directional field</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>dest_pos</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The positional encoding at the destination node, used to compute the directional field</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>h_in</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The input features of the layer, before any operation.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>dir_idx</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>The index of the positional encoding (<span class="arithmatex">\(k\)</span> in the equation above)</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>temperature</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[float]</code>
          </td>
          <td><p>The temperature to use in the softmax of the directional field.
If <code>None</code>, then the softmax is not applied on the field</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>h_mod</code></td>          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The aggregated features <span class="arithmatex">\(y^{(l)}\)</span></p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="goli.nn.dgl_layers.dgn_operations.get_grad_of_pos" class="doc doc-heading">
<code class="highlight language-python"><span class="n">get_grad_of_pos</span><span class="p">(</span><span class="n">source_pos</span><span class="p">,</span> <span class="n">dest_pos</span><span class="p">,</span> <span class="n">dir_idx</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.dgn_operations.get_grad_of_pos" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">
  
      <p>Get the vector field associated to the gradient of the positional
encoding.</p>
<div class="arithmatex">\[F_k = \nabla pos_k\]</div>
<p>or, if a temperature <span class="arithmatex">\(T\)</span> is provided</p>
<div class="arithmatex">\[F_k = softmax((\nabla pos_k)^+) - softmax((\nabla pos_k)^-)\]</div>
<p>Where <span class="arithmatex">\(F_k\)</span> is the <em>k-th</em> directional field associated to the <span class="arithmatex">\(k-th\)</span> positional
encoding.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>source_pos</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The positional encoding at the source node, used to compute the directional field</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>dest_pos</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>The positional encoding at the destination node, used to compute the directional field</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>h_in</code></td>
          <td>
          </td>
          <td><p>The input features of the layer, before any operation.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>dir_idx</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>The index of the positional encoding (<span class="arithmatex">\(k\)</span> in the equation above)</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>temperature</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[float]</code>
          </td>
          <td><p>The temperature to use in the softmax of the directional field.
If <code>None</code>, then the softmax is not applied on the field</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="goli.nn.dgl_layers.gat_dgl" class="doc doc-heading">
          <code>goli.nn.dgl_layers.gat_dgl</code>


<a href="#goli.nn.dgl_layers.gat_dgl" class="headerlink" title="Permanent link">&para;</a></h3>

  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="goli.nn.dgl_layers.gat_dgl.GATDgl" class="doc doc-heading">
        <code>GATDgl</code>


<a href="#goli.nn.dgl_layers.gat_dgl.GATDgl" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><a class="autorefs autorefs-internal" title="goli.nn.base_graph_layer.BaseGraphModule" href="goli.nn.html#goli.nn.base_graph_layer.BaseGraphModule">BaseGraphModule</a></code></p>




  

  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h5 id="goli.nn.dgl_layers.gat_dgl.GATDgl.layer_inputs_edges" class="doc doc-heading">
<code class="highlight language-python"><span class="n">layer_inputs_edges</span><span class="p">:</span> <span class="nb">bool</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#goli.nn.dgl_layers.gat_dgl.GATDgl.layer_inputs_edges" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Return a boolean specifying if the layer type
uses edges as input or not.
It is different from <code>layer_supports_edges</code> since a layer that
supports edges can decide to not use them.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>uses_edges</code></td>          <td>
                <code>bool</code>
          </td>
          <td><p>bool
Always <code>False</code> for the current class</p></td>
        </tr>
    </tbody>
  </table>
  </div>

</div>

<div class="doc doc-object doc-attribute">



<h5 id="goli.nn.dgl_layers.gat_dgl.GATDgl.layer_outputs_edges" class="doc doc-heading">
<code class="highlight language-python"><span class="n">layer_outputs_edges</span><span class="p">:</span> <span class="nb">bool</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#goli.nn.dgl_layers.gat_dgl.GATDgl.layer_outputs_edges" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Abstract method. Return a boolean specifying if the layer type
uses edges as input or not.
It is different from <code>layer_supports_edges</code> since a layer that
supports edges can decide to not use them.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>uses_edges</code></td>          <td>
                <code>bool</code>
          </td>
          <td><p>bool
Always <code>False</code> for the current class</p></td>
        </tr>
    </tbody>
  </table>
  </div>

</div>

<div class="doc doc-object doc-attribute">



<h5 id="goli.nn.dgl_layers.gat_dgl.GATDgl.out_dim_factor" class="doc doc-heading">
<code class="highlight language-python"><span class="n">out_dim_factor</span><span class="p">:</span> <span class="nb">int</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#goli.nn.dgl_layers.gat_dgl.GATDgl.out_dim_factor" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Get the factor by which the output dimension is multiplied for
the next layer.</p>
<p>For standard layers, this will return <code>1</code>.</p>
<p>But for others, such as <code>GatLayer</code>, the output is the concatenation
of the outputs from each head, so the out_dim gets multiplied by
the number of heads, and this function should return the number
of heads.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>dim_factor</code></td>          <td>
                <code>int</code>
          </td>
          <td><p>int
Always <code>self.num_heads</code> for the current class</p></td>
        </tr>
    </tbody>
  </table>
  </div>

</div>



<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.gat_dgl.GATDgl.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;elu&#39;</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">normalization</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.gat_dgl.GATDgl.__init__" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>GAT: Graph Attention Network
Graph Attention Networks (Velikovi et al., ICLR 2018)
<a href="https://arxiv.org/abs/1710.10903">https://arxiv.org/abs/1710.10903</a></p>
<p>The implementation is built on top of the DGL <code>GATCONV</code> layer</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>in_dim</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>int
Input feature dimensions of the layer</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>out_dim</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>int
Output feature dimensions of the layer</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>num_heads</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>int
Number of heads in Multi-Head Attention</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>activation</code></td>
          <td>
          </td>
          <td><p>str, Callable
activation function to use in the layer</p></td>
          <td>
                <code>&#39;elu&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>dropout</code></td>
          <td>
                <code>float</code>
          </td>
          <td><p>float
The ratio of units to dropout. Must be between 0 and 1</p></td>
          <td>
                <code>0.0</code>
          </td>
        </tr>
        <tr>
          <td><code>normalization</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[str, <span title="typing.Callable">Callable</span>]</code>
          </td>
          <td><p>Normalization to use. Choices:</p>
<ul>
<li>"none" or <code>None</code>: No normalization</li>
<li>"batch_norm": Batch normalization</li>
<li>"layer_norm": Layer normalization in the hidden layers.</li>
<li><code>Callable</code>: Any callable function</li>
</ul></td>
          <td>
                <code>&#39;none&#39;</code>
          </td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.gat_dgl.GATDgl.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.gat_dgl.GATDgl.forward" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Apply the graph convolutional layer, with the specified activations,
normalizations and dropout.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>g</code></td>
          <td>
                <code><span title="dgl.DGLGraph">DGLGraph</span></code>
          </td>
          <td><p>dgl.DGLGraph
graph on which the convolution is done</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>h</code></td>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p><code>torch.Tensor[..., N, Din]</code>
Node feature tensor, before convolution.
N is the number of nodes, Din is the input dimension <code>self.in_dim</code></p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p><code>torch.Tensor[..., N, Dout]</code>:
Node feature tensor, after convolution.
N is the number of nodes, Dout is the output dimension <code>self.out_dim</code></p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.gat_dgl.GATDgl.layer_supports_edges" class="doc doc-heading">
<code class="highlight language-python"><span class="n">layer_supports_edges</span><span class="p">()</span></code>

<a href="#goli.nn.dgl_layers.gat_dgl.GATDgl.layer_supports_edges" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Return a boolean specifying if the layer type supports edges or not.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>supports_edges</code></td>          <td>
                <code>bool</code>
          </td>
          <td><p>bool
Always <code>False</code> for the current class</p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>



  </div>

  </div>

</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="goli.nn.dgl_layers.gated_gcn_dgl" class="doc doc-heading">
          <code>goli.nn.dgl_layers.gated_gcn_dgl</code>


<a href="#goli.nn.dgl_layers.gated_gcn_dgl" class="headerlink" title="Permanent link">&para;</a></h3>

  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl" class="doc doc-heading">
        <code>GatedGCNDgl</code>


<a href="#goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><a class="autorefs autorefs-internal" title="goli.nn.base_graph_layer.BaseGraphModule" href="goli.nn.html#goli.nn.base_graph_layer.BaseGraphModule">BaseGraphModule</a></code></p>




  

  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h5 id="goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.layer_inputs_edges" class="doc doc-heading">
<code class="highlight language-python"><span class="n">layer_inputs_edges</span><span class="p">:</span> <span class="nb">bool</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.layer_inputs_edges" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Return a boolean specifying if the layer type
uses edges as input or not.
It is different from <code>layer_supports_edges</code> since a layer that
supports edges can decide to not use them.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>bool</code></td>          <td>
                <code>bool</code>
          </td>
          <td><p>Always <code>True</code> for the current class</p></td>
        </tr>
    </tbody>
  </table>
  </div>

</div>

<div class="doc doc-object doc-attribute">



<h5 id="goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.layer_outputs_edges" class="doc doc-heading">
<code class="highlight language-python"><span class="n">layer_outputs_edges</span><span class="p">:</span> <span class="nb">bool</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.layer_outputs_edges" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Abstract method. Return a boolean specifying if the layer type
uses edges as input or not.
It is different from <code>layer_supports_edges</code> since a layer that
supports edges can decide to not use them.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>bool</code></td>          <td>
                <code>bool</code>
          </td>
          <td><p>Always <code>True</code> for the current class</p></td>
        </tr>
    </tbody>
  </table>
  </div>

</div>

<div class="doc doc-object doc-attribute">



<h5 id="goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.out_dim_factor" class="doc doc-heading">
<code class="highlight language-python"><span class="n">out_dim_factor</span><span class="p">:</span> <span class="nb">int</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.out_dim_factor" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Get the factor by which the output dimension is multiplied for
the next layer.</p>
<p>For standard layers, this will return <code>1</code>.</p>
<p>But for others, such as <code>GatLayer</code>, the output is the concatenation
of the outputs from each head, so the out_dim gets multiplied by
the number of heads, and this function should return the number
of heads.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>int</code></td>          <td>
                <code>int</code>
          </td>
          <td><p>Always <code>1</code> for the current class</p></td>
        </tr>
    </tbody>
  </table>
  </div>

</div>



<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">in_dim_edges</span><span class="p">,</span> <span class="n">out_dim_edges</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">normalization</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.__init__" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>ResGatedGCN: Residual Gated Graph ConvNets
An Experimental Study of Neural Networks for Variable Graphs (Xavier Bresson and Thomas Laurent, ICLR 2018)
<a href="https://arxiv.org/pdf/1711.07553v2.pdf">https://arxiv.org/pdf/1711.07553v2.pdf</a></p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>in_dim</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Input feature dimensions of the layer</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>out_dim</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Output feature dimensions of the layer, and for the edges</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>in_dim_edges</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Input edge-feature dimensions of the layer</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>activation</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[<span title="typing.Callable">Callable</span>, str]</code>
          </td>
          <td><p>activation function to use in the layer</p></td>
          <td>
                <code>&#39;relu&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>dropout</code></td>
          <td>
                <code>float</code>
          </td>
          <td><p>The ratio of units to dropout. Must be between 0 and 1</p></td>
          <td>
                <code>0.0</code>
          </td>
        </tr>
        <tr>
          <td><code>normalization</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[str, <span title="typing.Callable">Callable</span>]</code>
          </td>
          <td><p>Normalization to use. Choices:</p>
<ul>
<li>"none" or <code>None</code>: No normalization</li>
<li>"batch_norm": Batch normalization</li>
<li>"layer_norm": Layer normalization</li>
<li><code>Callable</code>: Any callable function</li>
</ul></td>
          <td>
                <code>&#39;none&#39;</code>
          </td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.forward" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Apply the graph convolutional layer, with the specified activations,
normalizations and dropout.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>g</code></td>
          <td>
                <code><span title="dgl.DGLGraph">DGLGraph</span></code>
          </td>
          <td><p>graph on which the convolution is done</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>h</code></td>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p><code>torch.Tensor[..., N, Din]</code>
Node feature tensor, before convolution.
N is the number of nodes, Din is the input dimension <code>self.in_dim</code></p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>e</code></td>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p><code>torch.Tensor[..., N, Din_edges]</code>
Edge feature tensor, before convolution.
N is the number of nodes, Din is the input edge dimension  <code>self.in_dim_edges</code></p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p><code>torch.Tensor[..., N, Dout]</code>:
Node feature tensor, after convolution.
N is the number of nodes, Dout is the output dimension <code>self.out_dim</code></p></td>
        </tr>
        <tr>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p><code>torch.Tensor[..., N, Dout]</code>:
Edge feature tensor, after convolution.
N is the number of nodes, Dout_edges is the output edge dimension <code>self.out_dim</code></p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.layer_supports_edges" class="doc doc-heading">
<code class="highlight language-python"><span class="n">layer_supports_edges</span><span class="p">()</span></code>

<a href="#goli.nn.dgl_layers.gated_gcn_dgl.GatedGCNDgl.layer_supports_edges" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Return a boolean specifying if the layer type supports edges or not.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>bool</code></td>          <td>
                <code>bool</code>
          </td>
          <td><p>Always <code>True</code> for the current class</p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>



  </div>

  </div>

</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="goli.nn.dgl_layers.gcn_dgl" class="doc doc-heading">
          <code>goli.nn.dgl_layers.gcn_dgl</code>


<a href="#goli.nn.dgl_layers.gcn_dgl" class="headerlink" title="Permanent link">&para;</a></h3>

  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="goli.nn.dgl_layers.gcn_dgl.GCNDgl" class="doc doc-heading">
        <code>GCNDgl</code>


<a href="#goli.nn.dgl_layers.gcn_dgl.GCNDgl" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><a class="autorefs autorefs-internal" title="goli.nn.base_graph_layer.BaseGraphModule" href="goli.nn.html#goli.nn.base_graph_layer.BaseGraphModule">BaseGraphModule</a></code></p>




  

  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h5 id="goli.nn.dgl_layers.gcn_dgl.GCNDgl.layer_inputs_edges" class="doc doc-heading">
<code class="highlight language-python"><span class="n">layer_inputs_edges</span><span class="p">:</span> <span class="nb">bool</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#goli.nn.dgl_layers.gcn_dgl.GCNDgl.layer_inputs_edges" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Return a boolean specifying if the layer type
uses edges as input or not.
It is different from <code>layer_supports_edges</code> since a layer that
supports edges can decide to not use them.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>bool</code></td>          <td>
                <code>bool</code>
          </td>
          <td><p>Always <code>False</code> for the current class</p></td>
        </tr>
    </tbody>
  </table>
  </div>

</div>

<div class="doc doc-object doc-attribute">



<h5 id="goli.nn.dgl_layers.gcn_dgl.GCNDgl.layer_outputs_edges" class="doc doc-heading">
<code class="highlight language-python"><span class="n">layer_outputs_edges</span><span class="p">:</span> <span class="nb">bool</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#goli.nn.dgl_layers.gcn_dgl.GCNDgl.layer_outputs_edges" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Abstract method. Return a boolean specifying if the layer type
uses edges as input or not.
It is different from <code>layer_supports_edges</code> since a layer that
supports edges can decide to not use them.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>bool</code></td>          <td>
                <code>bool</code>
          </td>
          <td><p>Always <code>False</code> for the current class</p></td>
        </tr>
    </tbody>
  </table>
  </div>

</div>

<div class="doc doc-object doc-attribute">



<h5 id="goli.nn.dgl_layers.gcn_dgl.GCNDgl.out_dim_factor" class="doc doc-heading">
<code class="highlight language-python"><span class="n">out_dim_factor</span><span class="p">:</span> <span class="nb">int</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#goli.nn.dgl_layers.gcn_dgl.GCNDgl.out_dim_factor" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Get the factor by which the output dimension is multiplied for
the next layer.</p>
<p>For standard layers, this will return <code>1</code>.</p>
<p>But for others, such as <code>GatLayer</code>, the output is the concatenation
of the outputs from each head, so the out_dim gets multiplied by
the number of heads, and this function should return the number
of heads.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>int</code></td>          <td>
                <code>int</code>
          </td>
          <td><p>Always <code>1</code> for the current class</p></td>
        </tr>
    </tbody>
  </table>
  </div>

</div>



<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.gcn_dgl.GCNDgl.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">normalization</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.gcn_dgl.GCNDgl.__init__" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Graph convolutional network (GCN) layer from
Thomas N. Kipf, Max Welling, Semi-Supervised Classification with Graph Convolutional Networks (ICLR 2017)
<a href="http://arxiv.org/abs/1609.02907">http://arxiv.org/abs/1609.02907</a></p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>in_dim</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Input feature dimensions of the layer</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>out_dim</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Output feature dimensions of the layer</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>activation</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[str, <span title="typing.Callable">Callable</span>]</code>
          </td>
          <td><p>activation function to use in the layer</p></td>
          <td>
                <code>&#39;relu&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>dropout</code></td>
          <td>
                <code>float</code>
          </td>
          <td><p>The ratio of units to dropout. Must be between 0 and 1</p></td>
          <td>
                <code>0.0</code>
          </td>
        </tr>
        <tr>
          <td><code>normalization</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[str, <span title="typing.Callable">Callable</span>]</code>
          </td>
          <td><p>Normalization to use. Choices:</p>
<ul>
<li>"none" or <code>None</code>: No normalization</li>
<li>"batch_norm": Batch normalization</li>
<li>"layer_norm": Layer normalization</li>
<li><code>Callable</code>: Any callable function</li>
</ul></td>
          <td>
                <code>&#39;none&#39;</code>
          </td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.gcn_dgl.GCNDgl.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.gcn_dgl.GCNDgl.forward" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Apply the graph convolutional layer, with the specified activations,
normalizations and dropout.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>g</code></td>
          <td>
                <code><span title="dgl.DGLGraph">DGLGraph</span></code>
          </td>
          <td><p>graph on which the convolution is done</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>h</code></td>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p><code>torch.Tensor[..., N, Din]</code>
Node feature tensor, before convolution.
N is the number of nodes, Din is the input dimension <code>self.in_dim</code></p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p><code>torch.Tensor[..., N, Dout]</code>:
Node feature tensor, after convolution.
N is the number of nodes, Dout is the output dimension <code>self.out_dim</code></p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.gcn_dgl.GCNDgl.layer_supports_edges" class="doc doc-heading">
<code class="highlight language-python"><span class="n">layer_supports_edges</span><span class="p">()</span></code>

<a href="#goli.nn.dgl_layers.gcn_dgl.GCNDgl.layer_supports_edges" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Return a boolean specifying if the layer type supports edges or not.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>bool</code>
          </td>
          <td><p>bool
Always <code>False</code> for the current class</p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>



  </div>

  </div>

</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="goli.nn.dgl_layers.gin_dgl" class="doc doc-heading">
          <code>goli.nn.dgl_layers.gin_dgl</code>


<a href="#goli.nn.dgl_layers.gin_dgl" class="headerlink" title="Permanent link">&para;</a></h3>

  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="goli.nn.dgl_layers.gin_dgl.GINDgl" class="doc doc-heading">
        <code>GINDgl</code>


<a href="#goli.nn.dgl_layers.gin_dgl.GINDgl" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><a class="autorefs autorefs-internal" title="goli.nn.base_graph_layer.BaseGraphModule" href="goli.nn.html#goli.nn.base_graph_layer.BaseGraphModule">BaseGraphModule</a></code></p>




  

  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h5 id="goli.nn.dgl_layers.gin_dgl.GINDgl.layer_inputs_edges" class="doc doc-heading">
<code class="highlight language-python"><span class="n">layer_inputs_edges</span><span class="p">:</span> <span class="nb">bool</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#goli.nn.dgl_layers.gin_dgl.GINDgl.layer_inputs_edges" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Return a boolean specifying if the layer type
uses edges as input or not.
It is different from <code>layer_supports_edges</code> since a layer that
supports edges can decide to not use them.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>bool</code></td>          <td>
                <code>bool</code>
          </td>
          <td><p>Always <code>False</code> for the current class</p></td>
        </tr>
    </tbody>
  </table>
  </div>

</div>

<div class="doc doc-object doc-attribute">



<h5 id="goli.nn.dgl_layers.gin_dgl.GINDgl.layer_outputs_edges" class="doc doc-heading">
<code class="highlight language-python"><span class="n">layer_outputs_edges</span><span class="p">:</span> <span class="nb">bool</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#goli.nn.dgl_layers.gin_dgl.GINDgl.layer_outputs_edges" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Abstract method. Return a boolean specifying if the layer type
uses edges as input or not.
It is different from <code>layer_supports_edges</code> since a layer that
supports edges can decide to not use them.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>bool</code></td>          <td>
                <code>bool</code>
          </td>
          <td><p>Always <code>False</code> for the current class</p></td>
        </tr>
    </tbody>
  </table>
  </div>

</div>

<div class="doc doc-object doc-attribute">



<h5 id="goli.nn.dgl_layers.gin_dgl.GINDgl.out_dim_factor" class="doc doc-heading">
<code class="highlight language-python"><span class="n">out_dim_factor</span><span class="p">:</span> <span class="nb">int</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#goli.nn.dgl_layers.gin_dgl.GINDgl.out_dim_factor" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Get the factor by which the output dimension is multiplied for
the next layer.</p>
<p>For standard layers, this will return <code>1</code>.</p>
<p>But for others, such as <code>GatLayer</code>, the output is the concatenation
of the outputs from each head, so the out_dim gets multiplied by
the number of heads, and this function should return the number
of heads.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>int</code></td>          <td>
                <code>int</code>
          </td>
          <td><p>Always <code>1</code> for the current class</p></td>
        </tr>
    </tbody>
  </table>
  </div>

</div>



<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.gin_dgl.GINDgl.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">normalization</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">init_eps</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">learn_eps</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.gin_dgl.GINDgl.__init__" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>GIN: Graph Isomorphism Networks
HOW POWERFUL ARE GRAPH NEURAL NETWORKS? (Keyulu Xu, Weihua Hu, Jure Leskovec and Stefanie Jegelka, ICLR 2019)
<a href="https://arxiv.org/pdf/1810.00826.pdf">https://arxiv.org/pdf/1810.00826.pdf</a></p>
<p>[!] code adapted from dgl implementation of GINConv</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>in_dim</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Input feature dimensions of the layer</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>out_dim</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Output feature dimensions of the layer</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>activation</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[<span title="typing.Callable">Callable</span>, str]</code>
          </td>
          <td><p>activation function to use in the layer</p></td>
          <td>
                <code>&#39;relu&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>dropout</code></td>
          <td>
                <code>float</code>
          </td>
          <td><p>The ratio of units to dropout. Must be between 0 and 1</p></td>
          <td>
                <code>0.0</code>
          </td>
        </tr>
        <tr>
          <td><code>normalization</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[str, <span title="typing.Callable">Callable</span>]</code>
          </td>
          <td><p>Normalization to use. Choices:</p>
<ul>
<li>"none" or <code>None</code>: No normalization</li>
<li>"batch_norm": Batch normalization</li>
<li>"layer_norm": Layer normalization</li>
<li><code>Callable</code>: Any callable function</li>
</ul></td>
          <td>
                <code>&#39;none&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>init_eps</code></td>
          <td>
          </td>
          <td><p>Initial :math:<code>\epsilon</code> value, default: <code>0</code>.</p></td>
          <td>
                <code>0.0</code>
          </td>
        </tr>
        <tr>
          <td><code>learn_eps</code></td>
          <td>
          </td>
          <td><p>If True, :math:<code>\epsilon</code> will be a learnable parameter.</p></td>
          <td>
                <code>True</code>
          </td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.gin_dgl.GINDgl.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.gin_dgl.GINDgl.forward" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Apply the GIN convolutional layer, with the specified activations,
normalizations and dropout.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>g</code></td>
          <td>
                <code><span title="dgl.DGLGraph">DGLGraph</span></code>
          </td>
          <td><p>graph on which the convolution is done</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>h</code></td>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p><code>torch.Tensor[..., N, Din]</code>
Node feature tensor, before convolution.
N is the number of nodes, Din is the input dimension <code>self.in_dim</code></p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p><code>torch.Tensor[..., N, Dout]</code>:
Node feature tensor, after convolution.
N is the number of nodes, Dout is the output dimension <code>self.out_dim</code></p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.gin_dgl.GINDgl.layer_supports_edges" class="doc doc-heading">
<code class="highlight language-python"><span class="n">layer_supports_edges</span><span class="p">()</span></code>

<a href="#goli.nn.dgl_layers.gin_dgl.GINDgl.layer_supports_edges" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Return a boolean specifying if the layer type supports edges or not.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>supports_edges</code></td>          <td>
                <code>bool</code>
          </td>
          <td><p>bool
Always <code>False</code> for the current class</p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.gin_dgl.GINDgl.message_func" class="doc doc-heading">
<code class="highlight language-python"><span class="n">message_func</span><span class="p">(</span><span class="n">g</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.gin_dgl.GINDgl.message_func" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>If edge weights are provided, use them to weight the messages</p>

  </div>

</div>



  </div>

  </div>

</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="goli.nn.dgl_layers.pna_dgl" class="doc doc-heading">
          <code>goli.nn.dgl_layers.pna_dgl</code>


<a href="#goli.nn.dgl_layers.pna_dgl" class="headerlink" title="Permanent link">&para;</a></h3>

  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="goli.nn.dgl_layers.pna_dgl.BasePNADgl" class="doc doc-heading">
        <code>BasePNADgl</code>


<a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><a class="autorefs autorefs-internal" title="goli.nn.base_graph_layer.BaseGraphModule" href="goli.nn.html#goli.nn.base_graph_layer.BaseGraphModule">BaseGraphModule</a></code></p>




  

  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h5 id="goli.nn.dgl_layers.pna_dgl.BasePNADgl.layer_inputs_edges" class="doc doc-heading">
<code class="highlight language-python"><span class="n">layer_inputs_edges</span><span class="p">:</span> <span class="nb">bool</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.layer_inputs_edges" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Return a boolean specifying if the layer type
uses edges as input or not.
It is different from <code>layer_supports_edges</code> since a layer that
supports edges can decide to not use them.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>bool</code></td>          <td>
                <code>bool</code>
          </td>
          <td><p>Returns <code>self.edge_features</code></p></td>
        </tr>
    </tbody>
  </table>
  </div>

</div>

<div class="doc doc-object doc-attribute">



<h5 id="goli.nn.dgl_layers.pna_dgl.BasePNADgl.layer_outputs_edges" class="doc doc-heading">
<code class="highlight language-python"><span class="n">layer_outputs_edges</span><span class="p">:</span> <span class="nb">bool</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.layer_outputs_edges" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Abstract method. Return a boolean specifying if the layer type
uses edges as input or not.
It is different from <code>layer_supports_edges</code> since a layer that
supports edges can decide to not use them.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>bool</code></td>          <td>
                <code>bool</code>
          </td>
          <td><p>Always <code>False</code> for the current class</p></td>
        </tr>
    </tbody>
  </table>
  </div>

</div>

<div class="doc doc-object doc-attribute">



<h5 id="goli.nn.dgl_layers.pna_dgl.BasePNADgl.out_dim_factor" class="doc doc-heading">
<code class="highlight language-python"><span class="n">out_dim_factor</span><span class="p">:</span> <span class="nb">int</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.out_dim_factor" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Get the factor by which the output dimension is multiplied for
the next layer.</p>
<p>For standard layers, this will return <code>1</code>.</p>
<p>But for others, such as <code>GatLayer</code>, the output is the concatenation
of the outputs from each head, so the out_dim gets multiplied by
the number of heads, and this function should return the number
of heads.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>int</code></td>          <td>
                <code>int</code>
          </td>
          <td><p>Always <code>1</code> for the current class</p></td>
        </tr>
    </tbody>
  </table>
  </div>

</div>



<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.pna_dgl.BasePNADgl.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">aggregators</span><span class="p">,</span> <span class="n">scalers</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">normalization</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">avg_d</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">last_activation</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">in_dim_edges</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.__init__" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Abstract class used to standardize the implementation of PNA layers
in the current library.</p>
<p>PNA: Principal Neighbourhood Aggregation
Gabriele Corso, Luca Cavalleri, Dominique Beaini, Pietro Lio, Petar Velickovic
<a href="https://arxiv.org/abs/2004.05718">https://arxiv.org/abs/2004.05718</a></p>
<p>Method <code>layer_inputs_edges()</code> needs to be implemented in children classes</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>in_dim</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Input feature dimensions of the layer</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>out_dim</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Output feature dimensions of the layer</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>aggregators</code></td>
          <td>
                <code><span title="typing.List">List</span>[str]</code>
          </td>
          <td><p>Set of aggregation function identifiers,
e.g. "mean", "max", "min", "std", "sum", "var", "moment3".
The results from all aggregators will be concatenated.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>scalers</code></td>
          <td>
                <code><span title="typing.List">List</span>[str]</code>
          </td>
          <td><p>Set of scaling functions identifiers
e.g. "identidy", "amplification", "attenuation"
The results from all scalers will be concatenated</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>activation</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[<span title="typing.Callable">Callable</span>, str]</code>
          </td>
          <td><p>activation function to use in the layer</p></td>
          <td>
                <code>&#39;relu&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>dropout</code></td>
          <td>
                <code>float</code>
          </td>
          <td><p>The ratio of units to dropout. Must be between 0 and 1</p></td>
          <td>
                <code>0.0</code>
          </td>
        </tr>
        <tr>
          <td><code>normalization</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[str, <span title="typing.Callable">Callable</span>]</code>
          </td>
          <td><p>Normalization to use. Choices:</p>
<ul>
<li>"none" or <code>None</code>: No normalization</li>
<li>"batch_norm": Batch normalization</li>
<li>"layer_norm": Layer normalization</li>
<li><code>Callable</code>: Any callable function</li>
</ul></td>
          <td>
                <code>&#39;none&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>avg_d</code></td>
          <td>
                <code>float</code>
          </td>
          <td><p>Average degree of nodes in the training set, used by scalers to normalize</p></td>
          <td>
                <code>1.0</code>
          </td>
        </tr>
        <tr>
          <td><code>last_activation</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[<span title="typing.Callable">Callable</span>, str]</code>
          </td>
          <td><p>activation function to use in the last layer of the internal MLP</p></td>
          <td>
                <code>&#39;none&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>in_dim_edges</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>size of the edge features. If 0, edges are ignored</p></td>
          <td>
                <code>0</code>
          </td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.pna_dgl.BasePNADgl.add_virtual_graph_if_no_edges" class="doc doc-heading">
<code class="highlight language-python"><span class="n">add_virtual_graph_if_no_edges</span><span class="p">(</span><span class="n">g</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.add_virtual_graph_if_no_edges" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>When all elements of a given batch don't have any edges
(e.g. molecule with a single atom), the message function will
be skipped, and the number of features will be inconsistent due
to the variable number of aggregators.</p>
<p>To fix this issue, this method creates a new graph with self-loop
and appends it to the batch, only if all the elements of the batch
have degree 0.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>g</code></td>
          <td>
                <code><span title="dgl.DGLGraph">DGLGraph</span></code>
          </td>
          <td><p>The batched graphs</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>g</code></td>          <td>
                <code><span title="dgl.DGLGraph">DGLGraph</span></code>
          </td>
          <td><p>The batched graphs, with a possible new graph appended at the end</p></td>
        </tr>
        <tr>
<td><code>no_edges</code></td>          <td>
                <code>bool</code>
          </td>
          <td><p>Whether a graph was appended to the end of the batch
if all the elements of the batch had no edges.</p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.pna_dgl.BasePNADgl.layer_supports_edges" class="doc doc-heading">
<code class="highlight language-python"><span class="n">layer_supports_edges</span><span class="p">()</span></code>

<a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.layer_supports_edges" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Return a boolean specifying if the layer type supports edges or not.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>bool</code></td>          <td>
                <code>bool</code>
          </td>
          <td><p>Always <code>True</code> for the current class</p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.pna_dgl.BasePNADgl.message_func" class="doc doc-heading">
<code class="highlight language-python"><span class="n">message_func</span><span class="p">(</span><span class="n">edges</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.message_func" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>The message function to generate messages along the edges.</p>

  </div>

</div>

<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.pna_dgl.BasePNADgl.reduce_func" class="doc doc-heading">
<code class="highlight language-python"><span class="n">reduce_func</span><span class="p">(</span><span class="n">nodes</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.reduce_func" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>The reduce function to aggregate the messages.
Apply the aggregators and scalers, and concatenate the results.</p>

  </div>

</div>

<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.pna_dgl.BasePNADgl.remove_virtual_graph_if_no_edges" class="doc doc-heading">
<code class="highlight language-python"><span class="n">remove_virtual_graph_if_no_edges</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">no_edges</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl.remove_virtual_graph_if_no_edges" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>This removes the added graph from the method
<code>add_virtual_graph_if_no_edges</code>.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>g</code></td>
          <td>
                <code><span title="dgl.DGLGraph">DGLGraph</span></code>
          </td>
          <td><p>The batched graphs</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>no_edges</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>Whether to remove the last graph of the batch
if all the elements of the batch had no edges.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>g</code></td>          <td>
                <code><span title="dgl.DGLGraph">DGLGraph</span></code>
          </td>
          <td><p>The batched graphs, with a possible new graph appended at the end</p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="goli.nn.dgl_layers.pna_dgl.PNAConvolutionalDgl" class="doc doc-heading">
        <code>PNAConvolutionalDgl</code>


<a href="#goli.nn.dgl_layers.pna_dgl.PNAConvolutionalDgl" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><a class="autorefs autorefs-internal" title="goli.nn.dgl_layers.pna_dgl.BasePNADgl" href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl">BasePNADgl</a></code></p>

  
      <p>Implementation of the convolutional architecture of the PNA layer,
previously known as <code>PNASimpleLayer</code>. This layer aggregates the
neighbouring messages using multiple aggregators and scalers,
concatenates their results, then applies an MLP on the concatenated
features.</p>
<p>PNA: Principal Neighbourhood Aggregation
Gabriele Corso, Luca Cavalleri, Dominique Beaini, Pietro Lio, Petar Velickovic
<a href="https://arxiv.org/abs/2004.05718">https://arxiv.org/abs/2004.05718</a></p>



  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.pna_dgl.PNAConvolutionalDgl.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">aggregators</span><span class="p">,</span> <span class="n">scalers</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">normalization</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">avg_d</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;log&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">},</span> <span class="n">last_activation</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">posttrans_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">in_dim_edges</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.pna_dgl.PNAConvolutionalDgl.__init__" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>in_dim</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Input feature dimensions of the layer</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>out_dim</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Output feature dimensions of the layer</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>aggregators</code></td>
          <td>
                <code><span title="typing.List">List</span>[str]</code>
          </td>
          <td><p>Set of aggregation function identifiers,
e.g. "mean", "max", "min", "std", "sum", "var", "moment3".
The results from all aggregators will be concatenated.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>scalers</code></td>
          <td>
                <code><span title="typing.List">List</span>[str]</code>
          </td>
          <td><p>Set of scaling functions identifiers
e.g. "identidy", "amplification", "attenuation"
The results from all scalers will be concatenated</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>activation</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[<span title="typing.Callable">Callable</span>, str]</code>
          </td>
          <td><p>activation function to use in the layer</p></td>
          <td>
                <code>&#39;relu&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>dropout</code></td>
          <td>
                <code>float</code>
          </td>
          <td><p>The ratio of units to dropout. Must be between 0 and 1</p></td>
          <td>
                <code>0.0</code>
          </td>
        </tr>
        <tr>
          <td><code>normalization</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[str, <span title="typing.Callable">Callable</span>]</code>
          </td>
          <td><p>Normalization to use. Choices:</p>
<ul>
<li>"none" or <code>None</code>: No normalization</li>
<li>"batch_norm": Batch normalization</li>
<li>"layer_norm": Layer normalization</li>
<li><code>Callable</code>: Any callable function</li>
</ul></td>
          <td>
                <code>&#39;none&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>avg_d</code></td>
          <td>
                <code><span title="typing.Dict">Dict</span>[str, float]</code>
          </td>
          <td><p>Average degree of nodes in the training set, used by scalers to normalize</p></td>
          <td>
                <code>{&#39;log&#39;: 1.0}</code>
          </td>
        </tr>
        <tr>
          <td><code>last_activation</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[<span title="typing.Callable">Callable</span>, str]</code>
          </td>
          <td><p>activation function to use in the last layer of the internal MLP</p></td>
          <td>
                <code>&#39;none&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>posttrans_layers</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>number of layers in the MLP transformation after the aggregation</p></td>
          <td>
                <code>1</code>
          </td>
        </tr>
        <tr>
          <td><code>in_dim_edges</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>size of the edge features. If 0, edges are ignored</p></td>
          <td>
                <code>0</code>
          </td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.pna_dgl.PNAConvolutionalDgl.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">e</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.pna_dgl.PNAConvolutionalDgl.forward" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Apply the PNA convolutional layer, with the specified post transformation</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>g</code></td>
          <td>
                <code><span title="dgl.DGLGraph">DGLGraph</span></code>
          </td>
          <td><p>graph on which the convolution is done</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>h</code></td>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p><code>torch.Tensor[..., N, Din]</code>
Node feature tensor, before convolution.
N is the number of nodes, Din is the input dimension <code>self.in_dim</code></p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>e</code></td>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p><code>torch.Tensor[..., N, Din_edges]</code> or <code>None</code>
Edge feature tensor, before convolution.
N is the number of nodes, Din is the input edge dimension</p>
<p>Can be set to None if the layer does not use edge features
i.e. <code>self.layer_inputs_edges -&gt; False</code></p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p><code>torch.Tensor[..., N, Dout]</code>:
Node feature tensor, after convolution.
N is the number of nodes, Dout is the output dimension <code>self.out_dim</code></p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.pna_dgl.PNAConvolutionalDgl.pretrans_edges" class="doc doc-heading">
<code class="highlight language-python"><span class="n">pretrans_edges</span><span class="p">(</span><span class="n">edges</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.pna_dgl.PNAConvolutionalDgl.pretrans_edges" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Return a mapping to the features of the source nodes, concatenated to the
edge data.</p>

  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="goli.nn.dgl_layers.pna_dgl.PNAMessagePassingDgl" class="doc doc-heading">
        <code>PNAMessagePassingDgl</code>


<a href="#goli.nn.dgl_layers.pna_dgl.PNAMessagePassingDgl" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><a class="autorefs autorefs-internal" title="goli.nn.dgl_layers.pna_dgl.BasePNADgl" href="#goli.nn.dgl_layers.pna_dgl.BasePNADgl">BasePNADgl</a></code></p>

  
      <p>Implementation of the message passing architecture of the PNA message passing layer,
previously known as <code>PNALayerComplex</code>. This layer applies an MLP as
pretransformation to the concatenation of <span class="arithmatex">\([h_u, h_v, e_{uv}]\)</span> to generate
the messages, with <span class="arithmatex">\(h_u\)</span> the node feature, <span class="arithmatex">\(h_v\)</span> the neighbour node features,
and <span class="arithmatex">\(e_{uv}\)</span> the edge feature between the nodes <span class="arithmatex">\(u\)</span> and <span class="arithmatex">\(v\)</span>.</p>
<p>After the pre-transformation, it aggregates the messages
multiple aggregators and scalers,
concatenates their results, then applies an MLP on the concatenated
features.</p>
<p>PNA: Principal Neighbourhood Aggregation
Gabriele Corso, Luca Cavalleri, Dominique Beaini, Pietro Lio, Petar Velickovic
<a href="https://arxiv.org/abs/2004.05718">https://arxiv.org/abs/2004.05718</a></p>



  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.pna_dgl.PNAMessagePassingDgl.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">aggregators</span><span class="p">,</span> <span class="n">scalers</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">normalization</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">avg_d</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;log&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">},</span> <span class="n">last_activation</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">posttrans_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">pretrans_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">in_dim_edges</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.pna_dgl.PNAMessagePassingDgl.__init__" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>in_dim</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Input feature dimensions of the layer</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>out_dim</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Output feature dimensions of the layer</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>aggregators</code></td>
          <td>
                <code><span title="typing.List">List</span>[str]</code>
          </td>
          <td><p>Set of aggregation function identifiers,
e.g. "mean", "max", "min", "std", "sum", "var", "moment3".
The results from all aggregators will be concatenated.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>scalers</code></td>
          <td>
                <code><span title="typing.List">List</span>[str]</code>
          </td>
          <td><p>Set of scaling functions identifiers
e.g. "identidy", "amplification", "attenuation"
The results from all scalers will be concatenated</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>activation</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[<span title="typing.Callable">Callable</span>, str]</code>
          </td>
          <td><p>activation function to use in the layer</p></td>
          <td>
                <code>&#39;relu&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>dropout</code></td>
          <td>
                <code>float</code>
          </td>
          <td><p>The ratio of units to dropout. Must be between 0 and 1</p></td>
          <td>
                <code>0.0</code>
          </td>
        </tr>
        <tr>
          <td><code>normalization</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[str, <span title="typing.Callable">Callable</span>]</code>
          </td>
          <td><p>Normalization to use. Choices:</p>
<ul>
<li>"none" or <code>None</code>: No normalization</li>
<li>"batch_norm": Batch normalization</li>
<li>"layer_norm": Layer normalization</li>
<li><code>Callable</code>: Any callable function</li>
</ul></td>
          <td>
                <code>&#39;none&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>avg_d</code></td>
          <td>
                <code><span title="typing.Dict">Dict</span>[str, float]</code>
          </td>
          <td><p>Average degree of nodes in the training set, used by scalers to normalize</p></td>
          <td>
                <code>{&#39;log&#39;: 1.0}</code>
          </td>
        </tr>
        <tr>
          <td><code>last_activation</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[<span title="typing.Callable">Callable</span>, str]</code>
          </td>
          <td><p>activation function to use in the last layer of the internal MLP</p></td>
          <td>
                <code>&#39;none&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>posttrans_layers</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>number of layers in the MLP transformation after the aggregation</p></td>
          <td>
                <code>1</code>
          </td>
        </tr>
        <tr>
          <td><code>pretrans_layers</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>number of layers in the transformation before the aggregation</p></td>
          <td>
                <code>1</code>
          </td>
        </tr>
        <tr>
          <td><code>in_dim_edges</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>size of the edge features. If 0, edges are ignored</p></td>
          <td>
                <code>0</code>
          </td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.pna_dgl.PNAMessagePassingDgl.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">e</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.pna_dgl.PNAMessagePassingDgl.forward" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Apply the PNA Message passing layer, with the specified pre/post transformations</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>g</code></td>
          <td>
                <code><span title="dgl.DGLGraph">DGLGraph</span></code>
          </td>
          <td><p>graph on which the convolution is done</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>h</code></td>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p><code>torch.Tensor[..., N, Din]</code>
Node feature tensor, before convolution.
N is the number of nodes, Din is the input dimension <code>self.in_dim</code></p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>e</code></td>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p><code>torch.Tensor[..., N, Din_edges]</code> or <code>None</code>
Edge feature tensor, before convolution.
N is the number of nodes, Din is the input edge dimension</p>
<p>Can be set to None if the layer does not use edge features
i.e. <code>self.layer_inputs_edges -&gt; False</code></p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p><code>torch.Tensor[..., N, Dout]</code>:
Node feature tensor, after convolution.
N is the number of nodes, Dout is the output dimension <code>self.out_dim</code></p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.pna_dgl.PNAMessagePassingDgl.layer_supports_edges" class="doc doc-heading">
<code class="highlight language-python"><span class="n">layer_supports_edges</span><span class="p">()</span></code>

<a href="#goli.nn.dgl_layers.pna_dgl.PNAMessagePassingDgl.layer_supports_edges" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Return a boolean specifying if the layer type supports edges or not.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>bool</code></td>          <td>
                <code>bool</code>
          </td>
          <td><p>Always <code>True</code> for the current class</p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.pna_dgl.PNAMessagePassingDgl.pretrans_edges" class="doc doc-heading">
<code class="highlight language-python"><span class="n">pretrans_edges</span><span class="p">(</span><span class="n">edges</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.pna_dgl.PNAMessagePassingDgl.pretrans_edges" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Return a mapping to the concatenation of the features from
the source node, the destination node, and the edge between them (if applicable).</p>

  </div>

</div>



  </div>

  </div>

</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="goli.nn.dgl_layers.pna_operations" class="doc doc-heading">
          <code>goli.nn.dgl_layers.pna_operations</code>


<a href="#goli.nn.dgl_layers.pna_operations" class="headerlink" title="Permanent link">&para;</a></h3>

  <div class="doc doc-contents first">

  

  <div class="doc doc-children">











  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="goli.nn.dgl_layers.pooling_dgl" class="doc doc-heading">
          <code>goli.nn.dgl_layers.pooling_dgl</code>


<a href="#goli.nn.dgl_layers.pooling_dgl" class="headerlink" title="Permanent link">&para;</a></h3>

  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="goli.nn.dgl_layers.pooling_dgl.DirPoolingDgl" class="doc doc-heading">
        <code>DirPoolingDgl</code>


<a href="#goli.nn.dgl_layers.pooling_dgl.DirPoolingDgl" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><span title="torch.nn">nn</span>.<span title="torch.nn.Module">Module</span></code></p>

  
      <p>Apply pooling over the nodes in the graph using a directional potential
with an inner product.</p>
<p>In most cases, this is a pooling using the Fiedler vector.
This is basically equivalent to computing a Fourier transform for the
Fiedler vector. Then, we use the absolute value due to the sign ambiguity</p>



  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.pooling_dgl.DirPoolingDgl.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">feat</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.pooling_dgl.DirPoolingDgl.forward" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Compute directional inner-product pooling, and return absolute value.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>graph</code></td>
          <td>
          </td>
          <td><p>DGLGraph
The graph. Must have the key <code>graph.ndata["pos_dir"]</code></p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>feat</code></td>
          <td>
          </td>
          <td><p>torch.Tensor
The input feature with shape :math:<code>(N, *)</code> where
:math:<code>N</code> is the number of nodes in the graph.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>readout</code></td>          <td>
          </td>
          <td><p>torch.Tensor
The output feature with shape :math:<code>(B, *)</code>, where
:math:<code>B</code> refers to the batch size.</p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="goli.nn.dgl_layers.pooling_dgl.LogSumPoolingDgl" class="doc doc-heading">
        <code>LogSumPoolingDgl</code>


<a href="#goli.nn.dgl_layers.pooling_dgl.LogSumPoolingDgl" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><span title="dgl.nn.pytorch.glob.AvgPooling">AvgPooling</span></code></p>

  
      <p>Apply pooling over the nodes in the graph using a mean aggregation,
but scaled by the log of the number of nodes. This gives the same
expressive power as the sum, but helps deal with graphs that are
significantly larger than others by using a logarithmic scale.</p>
<div class="arithmatex">\[r^{(i)} = \frac{\log N_i}{N_i}\sum_{k=1}^{N_i} x^{(i)}_k\]</div>



  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.pooling_dgl.LogSumPoolingDgl.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">feat</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.pooling_dgl.LogSumPoolingDgl.forward" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Compute log-sum pooling.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>graph</code></td>
          <td>
          </td>
          <td><p>DGLGraph
The graph.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>feat</code></td>
          <td>
          </td>
          <td><p>torch.Tensor
The input feature with shape :math:<code>(N, *)</code> where
:math:<code>N</code> is the number of nodes in the graph.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>readout</code></td>          <td>
          </td>
          <td><p>torch.Tensor
The output feature with shape :math:<code>(B, *)</code>, where
:math:<code>B</code> refers to the batch size.</p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="goli.nn.dgl_layers.pooling_dgl.MinPoolingDgl" class="doc doc-heading">
        <code>MinPoolingDgl</code>


<a href="#goli.nn.dgl_layers.pooling_dgl.MinPoolingDgl" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><span title="dgl.nn.pytorch.glob.MaxPooling">MaxPooling</span></code></p>

  
      <p>Apply min pooling over the nodes in the graph.</p>
<div class="arithmatex">\[r^{(i)} = \min_{k=1}^{N_i}\left( x^{(i)}_k \right)\]</div>



  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.pooling_dgl.MinPoolingDgl.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">feat</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.pooling_dgl.MinPoolingDgl.forward" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Compute max pooling.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>graph</code></td>
          <td>
          </td>
          <td><p>DGLGraph
The graph.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>feat</code></td>
          <td>
          </td>
          <td><p>torch.Tensor
The input feature with shape :math:<code>(N, *)</code> where
:math:<code>N</code> is the number of nodes in the graph.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>readout</code></td>          <td>
          </td>
          <td><p>torch.Tensor
The output feature with shape :math:<code>(B, *)</code>, where
:math:<code>B</code> refers to the batch size.</p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="goli.nn.dgl_layers.pooling_dgl.S2SReadoutDgl" class="doc doc-heading">
        <code>S2SReadoutDgl</code>


<a href="#goli.nn.dgl_layers.pooling_dgl.S2SReadoutDgl" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><span title="torch.nn">nn</span>.<span title="torch.nn.Module">Module</span></code></p>

  
      <p>Performs a Set2Set aggregation of all the graph nodes' features followed by a series of fully connected layers</p>



  

  <div class="doc doc-children">











  </div>

  </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="goli.nn.dgl_layers.pooling_dgl.StdPoolingDgl" class="doc doc-heading">
        <code>StdPoolingDgl</code>


<a href="#goli.nn.dgl_layers.pooling_dgl.StdPoolingDgl" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><span title="torch.nn">nn</span>.<span title="torch.nn.Module">Module</span></code></p>

  
      <p>Apply standard deviation pooling over the nodes in the graph.</p>
<div class="arithmatex">\[r^{(i)} = \sigma_{k=1}^{N_i}\left( x^{(i)}_k \right)\]</div>



  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.pooling_dgl.StdPoolingDgl.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">feat</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.pooling_dgl.StdPoolingDgl.forward" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Compute standard deviation pooling.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>graph</code></td>
          <td>
          </td>
          <td><p>DGLGraph
The graph.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>feat</code></td>
          <td>
          </td>
          <td><p>torch.Tensor
The input feature with shape :math:<code>(N, *)</code> where
:math:<code>N</code> is the number of nodes in the graph.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
          </td>
          <td><p>torch.Tensor
The output feature with shape :math:<code>(B, *)</code>, where
:math:<code>B</code> refers to the batch size.</p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="goli.nn.dgl_layers.pooling_dgl.VirtualNodeDgl" class="doc doc-heading">
        <code>VirtualNodeDgl</code>


<a href="#goli.nn.dgl_layers.pooling_dgl.VirtualNodeDgl" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><span title="torch.nn">nn</span>.<span title="torch.nn.Module">Module</span></code></p>




  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.pooling_dgl.VirtualNodeDgl.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">in_dim_edges</span><span class="p">,</span> <span class="n">out_dim_edges</span><span class="p">,</span> <span class="n">vn_type</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">normalization</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">residual</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">use_edges</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.pooling_dgl.VirtualNodeDgl.__init__" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>The VirtualNode is a layer that pool the features of the graph,
applies a neural network layer on the pooled features,
then add the result back to the node features of every node.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>in_dim</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Input and output feature dimensions of the virtual node layer</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>activation</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[str, <span title="typing.Callable">Callable</span>]</code>
          </td>
          <td><p>activation function to use in the neural network layer.</p></td>
          <td>
                <code>&#39;relu&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>dropout</code></td>
          <td>
                <code>float</code>
          </td>
          <td><p>The ratio of units to dropout. Must be between 0 and 1</p></td>
          <td>
                <code>0.0</code>
          </td>
        </tr>
        <tr>
          <td><code>normalization</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[str, <span title="typing.Callable">Callable</span>]</code>
          </td>
          <td><p>Normalization to use. Choices:</p>
<ul>
<li>"none" or <code>None</code>: No normalization</li>
<li>"batch_norm": Batch normalization</li>
<li>"layer_norm": Layer normalization</li>
<li><code>Callable</code>: Any callable function</li>
</ul></td>
          <td>
                <code>&#39;none&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>bias</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>Whether to add a bias to the neural network</p></td>
          <td>
                <code>True</code>
          </td>
        </tr>
        <tr>
          <td><code>residual</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>Whether all virtual nodes should be connected together
via a residual connection</p></td>
          <td>
                <code>True</code>
          </td>
        </tr>
        <tr>
          <td><code>out_dim</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>NOT USED: Out node dimmension for virtual node pooling</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>in_dim_edges</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>NOT USED: Edge dimmension for virtual node pooling</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>out_dim_edges</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>NOT USED: Edge dimmension for virtual node pooling</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>use_edges</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>NOT USED: boolean to choose using edges or not in virtual node</p></td>
          <td>
                <code>False</code>
          </td>
        </tr>
    </tbody>
  </table>

  </div>

</div>

<div class="doc doc-object doc-function">



<h5 id="goli.nn.dgl_layers.pooling_dgl.VirtualNodeDgl.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">vn_h</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.pooling_dgl.VirtualNodeDgl.forward" class="headerlink" title="Permanent link">&para;</a></h5>


  <div class="doc doc-contents ">
  
      <p>Apply the virtual node layer.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>g</code></td>
          <td>
                <code>dgl.<span title="dgl.DGLGraph">DGLGraph</span></code>
          </td>
          <td><p>graph on which the convolution is done</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>h</code></td>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span>[..., N, Din]</code>
          </td>
          <td><p>Node feature tensor, before convolution.
<code>N</code> is the number of nodes, <code>Din</code> is the input features</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>vn_h</code></td>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span>[..., M, Din]</code>
          </td>
          <td><p>Graph feature of the previous virtual node, or <code>None</code>
<code>M</code> is the number of graphs, <code>Din</code> is the input features.
It is added to the result after the MLP, as a residual connection</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p><code>h = torch.Tensor[..., N, Dout]</code>:
Node feature tensor, after convolution and residual.
<code>N</code> is the number of nodes, <code>Dout</code> is the output features of the layer and residual</p></td>
        </tr>
        <tr>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p><code>vn_h = torch.Tensor[..., M, Dout]</code>:
Graph feature tensor to be used at the next virtual node, or <code>None</code>
<code>M</code> is the number of graphs, <code>Dout</code> is the output features</p></td>
        </tr>
    </tbody>
  </table>

  </div>

</div>



  </div>

  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="goli.nn.dgl_layers.pooling_dgl.parse_pooling_layer_dgl" class="doc doc-heading">
<code class="highlight language-python"><span class="n">parse_pooling_layer_dgl</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">pooling</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#goli.nn.dgl_layers.pooling_dgl.parse_pooling_layer_dgl" class="headerlink" title="Permanent link">&para;</a></h4>


  <div class="doc doc-contents ">
  
      <p>Select the pooling layers from a list of strings, and put them
in a Module that concatenates their outputs.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>in_dim</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>The dimension at the input layer of the pooling</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>pooling</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[str, <span title="typing.List">List</span>[str]]</code>
          </td>
          <td><p>The list of pooling layers to use. The accepted strings are:</p>
<ul>
<li>"sum": <code>SumPooling</code></li>
<li>"mean": <code>MeanPooling</code></li>
<li>"max": <code>MaxPooling</code></li>
<li>"min": <code>MinPooling</code></li>
<li>"std": <code>StdPooling</code></li>
<li>"s2s": <code>Set2Set</code></li>
<li>"dir{int}": <code>DirPooling</code></li>
</ul></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  </div>

</div>



  </div>

  </div>

</div>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright 2020 - 2023 Valence Discovery
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.expand"], "search": "../../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.efa0ade1.min.js"></script>
      
        <script src="../../javascripts/config.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>