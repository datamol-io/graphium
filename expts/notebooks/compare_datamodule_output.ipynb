{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'labels': DataBatch(graph_zinc=[1, 3], x=[24, 1], edge_index=[2, 52], graph_qm9=[1, 19], graph_tox21=[1, 12], batch=[24], ptr=[2]),\n",
       "  'features': DataBatch(edge_index=[2, 52], edge_weight=[52], num_nodes=24, feat=[24, 85], edge_feat=[52, 13], laplacian_eigvec=[24, 8], laplacian_eigval=[24, 8], rw_return_probs=[24, 16], batch=[24], ptr=[2])},\n",
       " {'labels': DataBatch(graph_zinc=[1, 3], x=[21, 1], edge_index=[2, 46], graph_tox21=[1, 12], graph_qm9=[1, 19], batch=[21], ptr=[2]),\n",
       "  'features': DataBatch(edge_index=[2, 46], edge_weight=[46], num_nodes=21, feat=[21, 85], edge_feat=[46, 13], laplacian_eigvec=[21, 8], laplacian_eigval=[21, 8], rw_return_probs=[21, 16], batch=[21], ptr=[2])}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphium2 = pickle.load(open(\"val_graphs_graphium2_new.pkl\", \"rb\"))\n",
    "graphium2[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'labels': DataBatch(graph_qm9=[1, 19], graph_zinc=[1, 3], graph_tox21=[1, 12]),\n",
       "  'features': DataBatch(edge_index=[2, 16], edge_weight=[16], num_nodes=8, feat=[8, 85], edge_feat=[16, 13], laplacian_eigvec=[8, 8], laplacian_eigval=[8, 8], rw_return_probs=[8, 16], batch=[8], ptr=[2])},\n",
       " {'labels': DataBatch(graph_zinc=[1, 3], graph_qm9=[1, 19], graph_tox21=[1, 12]),\n",
       "  'features': DataBatch(edge_index=[2, 42], edge_weight=[42], num_nodes=20, feat=[20, 85], edge_feat=[42, 13], laplacian_eigvec=[20, 8], laplacian_eigval=[20, 8], rw_return_probs=[20, 16], batch=[20], ptr=[2])}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphium3 = pickle.load(open(\"val_graphs_graphium3_new.pkl\", \"rb\"))\n",
    "graphium3[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_same_graph(graph1, graph2, tolerance=0.1):\n",
    "    \"\"\"\n",
    "    Check if two graphs are the same by comparing the shape of their features, and the values of their labels.\n",
    "    \"\"\"\n",
    "\n",
    "    num_nodes1 = graph1[\"features\"].num_nodes\n",
    "    num_nodes2 = graph2[\"features\"].num_nodes\n",
    "    num_edges1 = graph1[\"features\"].num_edges\n",
    "    num_edges2 = graph2[\"features\"].num_edges\n",
    "    if (num_nodes1 != num_nodes2) or (num_edges1 != num_edges2):\n",
    "        return False\n",
    "\n",
    "    qm9_1 = graph1[\"labels\"][\"graph_qm9\"]\n",
    "    tox21_1 = graph1[\"labels\"][\"graph_tox21\"]\n",
    "    zinc_1 = graph1[\"labels\"][\"graph_zinc\"]\n",
    "    qm9_2 = graph2[\"labels\"][\"graph_qm9\"]\n",
    "    tox21_2 = graph2[\"labels\"][\"graph_tox21\"]\n",
    "    zinc_2 = graph2[\"labels\"][\"graph_zinc\"]\n",
    "\n",
    "\n",
    "    if (qm9_1.shape != qm9_2.shape) or (tox21_1.shape != tox21_2.shape) or (zinc_1.shape != zinc_2.shape):\n",
    "        return False\n",
    "\n",
    "    qm9_1 = qm9_1[~qm9_1.isnan()]\n",
    "    tox21_1 = tox21_1[~tox21_1.isnan()]\n",
    "    zinc_1 = zinc_1[~zinc_1.isnan()]\n",
    "    qm9_2 = qm9_2[~qm9_2.isnan()]\n",
    "    tox21_2 = tox21_2[~tox21_2.isnan()]\n",
    "    zinc_2 = zinc_2[~zinc_2.isnan()]\n",
    "\n",
    "    if (qm9_1.shape != qm9_2.shape) or (tox21_1.shape != tox21_2.shape) or (zinc_1.shape != zinc_2.shape):\n",
    "        return False\n",
    "        \n",
    "    if not torch.allclose(qm9_1, qm9_2, atol=tolerance):\n",
    "        return False\n",
    "    if not torch.allclose(tox21_1, tox21_2, atol=tolerance):\n",
    "        return False\n",
    "    if not torch.allclose(zinc_1, zinc_2, atol=tolerance):\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "    \n",
    "\n",
    "def non_empty_label(graph):\n",
    "    qm9 = graph[\"labels\"][\"graph_qm9\"]\n",
    "    tox21 = graph[\"labels\"][\"graph_tox21\"]\n",
    "    zinc = graph[\"labels\"][\"graph_zinc\"]\n",
    "\n",
    "    non_empty = []\n",
    "\n",
    "    if not torch.all(qm9.isnan()):\n",
    "        non_empty.append(\"qm9\")\n",
    "    if not torch.all(tox21.isnan()):\n",
    "        non_empty.append(\"tox21\")\n",
    "    if not torch.all(zinc.isnan()):\n",
    "        non_empty.append(\"zinc\")\n",
    "\n",
    "    return non_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (1, 1), (2, 2), (3, 3), (4, 4)]\n",
      "30 / 30\n"
     ]
    }
   ],
   "source": [
    "# Validate function by checking that each graph is ONLY the same as itself, for the graphium2 graphs\n",
    "matches = []\n",
    "for ii, g in enumerate(graphium2):\n",
    "    for jj, gg in enumerate(graphium2):\n",
    "        if is_same_graph(g, gg):\n",
    "            matches.append((ii, jj))\n",
    "print(matches[:5])\n",
    "matches_ten = torch.as_tensor(matches)\n",
    "print((matches_ten[:, 0] == matches_ten[:, 1]).sum().tolist(), \"/\", len(matches_ten))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (1, 1), (2, 2), (3, 3), (4, 4)]\n",
      "30 / 30\n"
     ]
    }
   ],
   "source": [
    "# Validate function by checking that each graph is ONLY the same as itself, for the graphium3 graphs\n",
    "matches = []\n",
    "for ii, g in enumerate(graphium3):\n",
    "    for jj, gg in enumerate(graphium3):\n",
    "        if is_same_graph(g, gg):\n",
    "            matches.append((ii, jj))\n",
    "print(matches[:5])\n",
    "matches_ten = torch.as_tensor(matches)\n",
    "print((matches_ten[:, 0] == matches_ten[:, 1]).sum().tolist(), \"/\", len(matches_ten))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 15 Found match ['zinc']\n",
      "1 14 Found match ['zinc']\n",
      "2 13 Found match ['tox21']\n",
      "3 5 Found match ['tox21']\n",
      "5 25 Found match ['tox21']\n",
      "6 2 Found match ['tox21']\n",
      "8 8 Found match ['tox21']\n",
      "11 22 Found match ['tox21']\n",
      "12 18 Found match ['tox21']\n",
      "23 17 Found match ['tox21']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 15),\n",
       " (1, 14),\n",
       " (2, 13),\n",
       " (3, 5),\n",
       " (5, 25),\n",
       " (6, 2),\n",
       " (8, 8),\n",
       " (11, 22),\n",
       " (12, 18),\n",
       " (23, 17)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the matches between the two datasets from graphium2 and graphium3\n",
    "matches = []\n",
    "for ii, g2 in enumerate(graphium2):\n",
    "    for jj, g3 in enumerate(graphium3):\n",
    "        if is_same_graph(g2, g3):\n",
    "            print(ii, jj, \"Found match\", non_empty_label(g2))\n",
    "            matches.append((ii, jj))\n",
    "        # else:\n",
    "        #     print(ii, jj, \"No Match\")\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphium 2 \n",
      "_________________________\n",
      "7 tensor([-1.0777,  0.9168,  0.2093,  0.4276, -0.0869], dtype=torch.float64)\n",
      "9 tensor([-0.6980,  1.8550,  2.3131, -1.4528,  0.6577], dtype=torch.float64)\n",
      "10 tensor([ 3.5083, -0.8910,  0.4519, -1.9198, -0.1023], dtype=torch.float64)\n",
      "14 tensor([ 0.6422, -0.9315,  0.0098, -1.3373,  0.3904], dtype=torch.float64)\n",
      "16 tensor([ 2.7967, -2.0454, -1.4393, -0.4990, -0.2233], dtype=torch.float64)\n",
      "17 tensor([-0.7930,  2.7671,  3.6079, -0.9251, -0.1265], dtype=torch.float64)\n",
      "19 tensor([ 0.4698, -0.1997, -0.3652, -0.3209, -0.3607], dtype=torch.float64)\n",
      "25 tensor([ 2.0471,  1.0800,  1.0429, -0.8319,  0.3090], dtype=torch.float64)\n",
      "27 tensor([-0.6739, -0.1215,  0.4055,  0.5390,  0.7896], dtype=torch.float64)\n",
      "28 tensor([ 1.8100,  6.9263,  4.9668,  0.1054, -1.6760], dtype=torch.float64)\n",
      "\n",
      "\n",
      "Graphium 3 \n",
      "_________________________\n",
      "0 tensor([ 1.8190, -0.8910,  0.4519, -1.7172, -0.1023], dtype=torch.float64)\n",
      "10 tensor([ 0.6422, -0.9315,  0.0098, -1.3373,  0.3904], dtype=torch.float64)\n",
      "11 tensor([-0.6980,  1.0072,  1.3694, -1.4528,  0.6577], dtype=torch.float64)\n",
      "12 tensor([ 1.8190,  1.0072,  1.0429, -0.8319,  0.3090], dtype=torch.float64)\n",
      "16 tensor([-0.7930,  1.0072,  1.3694, -0.9251, -0.1265], dtype=torch.float64)\n",
      "19 tensor([ 1.8190, -1.8173, -1.4393, -0.4990, -0.2233], dtype=torch.float64)\n",
      "21 tensor([ 0.4698, -0.1997, -0.3652, -0.3209, -0.3607], dtype=torch.float64)\n",
      "26 tensor([ 1.8100,  1.0072,  1.3694,  0.1054, -1.6112], dtype=torch.float64)\n",
      "28 tensor([-0.6739, -0.1215,  0.4055,  0.5390,  0.7896], dtype=torch.float64)\n",
      "29 tensor([-1.0414,  0.9168,  0.2093,  0.4276, -0.0869], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Since their are no matches for QM9, print their labels to visually inspect\n",
    "\n",
    "LABEL = \"qm9\"\n",
    "print(\"Graphium 2 \\n_________________________\")\n",
    "for ii, g2 in enumerate(graphium2):\n",
    "    if LABEL in non_empty_label(g2):\n",
    "        print(ii, g2[\"labels\"][f\"graph_{LABEL}\"][0, :5])\n",
    "\n",
    "print(\"\\n\\nGraphium 3 \\n_________________________\")\n",
    "for ii, g3 in enumerate(graphium3):\n",
    "    if LABEL in non_empty_label(g3):\n",
    "        print(ii, g3[\"labels\"][f\"graph_{LABEL}\"][0, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def find_row_mapping(graph1, graph2, p: float = 2.0) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Find which rows in graph1 correspond to which rows in graph2 using the Hungarian algorithm.\n",
    "\n",
    "    Given two 2D tensors A and B of shape (n, d), this function returns a tensor of shape (n, 2)\n",
    "    where each row [i, j] indicates that the i-th row of A corresponds to the j-th row of B.\n",
    "    \n",
    "    Parameters:\n",
    "      A (torch.Tensor): A tensor of shape (n, d)\n",
    "      B (torch.Tensor): A tensor of shape (n, d)\n",
    "      p (float): The norm degree to use in torch.cdist (default is 2 for Euclidean distance).\n",
    "    \n",
    "    Returns:\n",
    "      torch.Tensor: A tensor of shape (n, 2) containing the mapping pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    # Concatenate the deterministic node features \"feat\", Laplacian eigenvalues, and random walk return probabilities\n",
    "    A = torch.cat([graph1[\"features\"][\"feat\"], graph1[\"features\"][\"laplacian_eigval\"], graph1[\"features\"][\"rw_return_probs\"]], dim=1).float()\n",
    "    B = torch.cat([graph2[\"features\"][\"feat\"], graph2[\"features\"][\"laplacian_eigval\"], graph2[\"features\"][\"rw_return_probs\"]], dim=1).float()\n",
    "\n",
    "    # Compute the pairwise cost matrix (squared Euclidean distances)\n",
    "    cost_matrix = torch.cdist(A, B, p=p) ** 2  # Shape: (n, n)\n",
    "\n",
    "    # Convert cost matrix to NumPy array for the Hungarian algorithm\n",
    "    cost_np = cost_matrix.cpu().numpy()\n",
    "\n",
    "    # Solve the assignment problem using SciPy's linear_sum_assignment (Hungarian algorithm)\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_np)\n",
    "\n",
    "    # Gather the error (cost) for each assignment pair\n",
    "    errors = cost_matrix[row_ind, col_ind]\n",
    "\n",
    "    # Stack the row indices, column indices, and error values into a mapping tensor of shape (n, 3)\n",
    "    mapping = torch.stack([torch.tensor(row_ind), torch.tensor(col_ind), errors], dim=1)\n",
    "    return mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  0.,  0.],\n",
      "        [ 1., 21.,  0.],\n",
      "        [ 2.,  7.,  0.],\n",
      "        [ 3., 22.,  0.],\n",
      "        [ 4., 23.,  0.]]) \n",
      "Distances sum to 0.0\n",
      "tensor([[ 0.,  0.,  0.],\n",
      "        [ 1.,  2.,  0.],\n",
      "        [ 2.,  5.,  0.],\n",
      "        [ 3., 19.,  0.],\n",
      "        [ 4., 14.,  0.]]) \n",
      "Distances sum to 0.0\n",
      "tensor([[ 0.,  0.,  0.],\n",
      "        [ 1.,  8.,  0.],\n",
      "        [ 2., 11.,  0.],\n",
      "        [ 3., 19.,  0.],\n",
      "        [ 4., 18.,  0.]]) \n",
      "Distances sum to 0.0\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 8., 0.],\n",
      "        [2., 9., 0.],\n",
      "        [3., 3., 0.],\n",
      "        [4., 1., 0.]]) \n",
      "Distances sum to 0.0\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 7., 0.],\n",
      "        [2., 5., 0.],\n",
      "        [3., 2., 0.],\n",
      "        [4., 8., 0.]]) \n",
      "Distances sum to 0.0\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 9., 0.],\n",
      "        [2., 4., 0.],\n",
      "        [3., 1., 0.],\n",
      "        [4., 7., 0.]]) \n",
      "Distances sum to 0.0\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 8., 0.],\n",
      "        [2., 9., 0.],\n",
      "        [3., 2., 0.],\n",
      "        [4., 3., 0.]]) \n",
      "Distances sum to 0.0\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 2., 0.],\n",
      "        [2., 5., 0.],\n",
      "        [3., 7., 0.],\n",
      "        [4., 4., 0.]]) \n",
      "Distances sum to 0.0\n",
      "tensor([[ 0.,  0.,  0.],\n",
      "        [ 1., 19.,  0.],\n",
      "        [ 2.,  4.,  0.],\n",
      "        [ 3., 16.,  0.],\n",
      "        [ 4.,  8.,  0.]]) \n",
      "Distances sum to 0.0\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 4., 0.],\n",
      "        [2., 5., 0.],\n",
      "        [3., 3., 0.],\n",
      "        [4., 9., 0.]]) \n",
      "Distances sum to 1.1368683772161603e-13\n"
     ]
    }
   ],
   "source": [
    "# For the molecules that matched, check if we can find a mapping between the node features on the rows.\n",
    "# We actually find that there is always a perfect match, but the order of the rows is different.\n",
    "# First column is the order in graph1, second is order in graph2, third is the error (distance) between the rows.\n",
    "# We see the distance is always 0\n",
    "for match in matches:\n",
    "    mapping = find_row_mapping(graphium2[match[0]], graphium3[match[1]])\n",
    "    print(mapping[:5], f\"\\nDistances sum to {mapping[:, 2].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.     0.     0.     0.     0.     0.     0.     0.0487]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.     0.     0.     0.2756 0.2229 0.     0.     0.    ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.     0.     0.3613 0.2842 0.     0.1685 0.1224 0.    ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# For the molecules that matched, visually inspect their laplacian eigenvectors and compute their differences\n",
    "for match in matches:\n",
    "    mapping = find_row_mapping(graphium2[match[0]], graphium3[match[1]])\n",
    "    eigvec2 = graphium2[match[0]][\"features\"][\"laplacian_eigvec\"][mapping[:, 0].long()]\n",
    "    eigvec3 = graphium3[match[1]][\"features\"][\"laplacian_eigvec\"][mapping[:, 1].long()]\n",
    "    print(((eigvec2.abs() - eigvec3.abs()).abs().mean(dim=0)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphium3_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
