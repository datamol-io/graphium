# @package _global_

predictor:
  metrics_on_progress_bar:
    pcqm4m_g25: []
  metrics_on_training_set:
    pcqm4m_g25: []
  loss_fun:
    pcqm4m_g25: mae_ipu

metrics:
  pcqm4m_g25:
    - name: mae
      metric: mae_ipu
      target_nan_mask: null
      multitask_handling: mean-per-label
      threshold_kwargs: null
    - name: pearsonr
      metric: pearsonr_ipu
      threshold_kwargs: null
      target_nan_mask: null
      multitask_handling: mean-per-label
    - name: r2
      metric: r2_score_ipu
      threshold_kwargs: null
      target_nan_mask: null
      multitask_handling: mean-per-label

datamodule:
  args: # Matches that in the test_multitask_datamodule.py case.
    task_specific_args:   # To be replaced by a new class "DatasetParams"
      pcqm4m_g25:
        df: null
        df_path: ../data/graphium/large-dataset/PCQM4M_G25_N4.parquet
        # wget https://storage.googleapis.com/graphium-public/datasets/neurips_2023/Large-dataset/PCQM4M_G25_N4.parquet
        # or set path as the URL directly
        smiles_col: "ordered_smiles"
        label_cols: graph_*  # graph_* means all columns starting with "graph_"
        # sample_size: 2000 # use sample_size for test
        task_level: graph
        splits_path: ../data/graphium/large-dataset/pcqm4m_g25_n4_random_splits.pt  # Download with `wget https://storage.googleapis.com/graphium-public/datasets/neurips_2023/Large-dataset/pcqm4m_g25_n4_random_splits.pt`
        # split_names: [train, val, test_seen]
        label_normalization:
          normalize_val_test: True
          method: "normal"
        epoch_sampling_fraction: 1.0